<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>bits and pieces on bits-pieces</title><link>https://l10178.github.io/bits-pieces/</link><description>Recent content in bits and pieces on bits-pieces</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Fri, 19 Mar 2021 23:54:37 +0800</lastBuildDate><atom:link href="https://l10178.github.io/bits-pieces/index.xml" rel="self" type="application/rss+xml"/><item><title>Git常用配置</title><link>https://l10178.github.io/bits-pieces/linux/git/</link><pubDate>Thu, 09 Mar 2023 23:54:37 +0800</pubDate><guid>https://l10178.github.io/bits-pieces/linux/git/</guid><description>Git 多用户配置 Git 给不同目录配置不同的 config，比如区分个人开发账号和公司开发账号。
为账户 B 准备一个单独的配置文件，比如： ~/.gitconfig-b，内容根据需要定义。
[user] name = userb-name email = userb-email@test.com 修改 ~/.gitconfig 文件，增加以下配置，引用上面创建的配置文件，注意用绝对路径，并且路径以 / 结尾。
[includeIf &amp;#34;gitdir:/project/path-b/&amp;#34;] path = /Users/xxxx/.gitconfig-b 保存后，在 /project/path-b/ 下新的仓库都会以 .gitconfig-b 中的用户名和邮箱提交了。</description></item><item><title>Envoy生产配置最佳实践</title><link>https://l10178.github.io/bits-pieces/kubernetes/envoy/</link><pubDate>Wed, 15 Feb 2023 21:54:37 +0800</pubDate><guid>https://l10178.github.io/bits-pieces/kubernetes/envoy/</guid><description>Envoy 监控指标 Envoy 将其指标分为以下主要类别：
Downstream：与进入代理的连接和请求相关的指标。它们由 listener、HTTP connection manager(HCM)、TCP proxy filter 等产生。 Upstream：与传出连接和代理发出的请求相关的指标。它们由 connection pool、router filter、tcp proxy filter 等产生。 Server：描述 Envoy 内部状态的指标。其中包括正常运行时间或分配的内存等指标。 Envoy 发出三种指标数据类型：
Counter(Counters)：无符号整数，只会增加而不会减少。例如，总请求。 仪表(Gauges)：增加和减少的无符号整数。例如，当前活动的请求。 Histograms(Histograms)：作为指标流的一部分的无符号整数，然后由收集器聚合以最终产生汇总的百分位值(percentile，即平常说的 P99/P50/Pxx)。例如，Upsteam 响应时间。 在 Envoy 的内部实现中，Counters 和 Gauges 被分批并定期刷新以提高性能，Histograms 在接收时写入。
从指标的产出地点来划分，可以分为：
cluster manager: 面向 upstream 的 L3/L4/L7 层指标。 http connection manager(HCM)： 面向 upstream &amp;amp; downstream 的 L7 层指标。 listeners: 面向 downstream 的 L3/L4 层指标。 server：全局。 Envoy 通过 admin 端口放开了 prometheus 格式的监控指标，可以通过 admin 接口快速查看当前已支持的指标：http://127.0.0.1:9901/stats/prometheus，其中 9901 是 admin 端口。</description></item><item><title>MySQL5.7升级至8.0</title><link>https://l10178.github.io/bits-pieces/devops/mysql5.7to8.0/</link><pubDate>Wed, 29 Dec 2021 23:54:37 +0800</pubDate><guid>https://l10178.github.io/bits-pieces/devops/mysql5.7to8.0/</guid><description>MySQL 5.7 升级至 8.0，程序适配以及踩坑记录。
代码适配方案 mysql-connector-java.jar 升级到 8.0.21 版本。 com.mysql.jdbc.Driver 更换为 com.mysql.cj.jdbc.Driver。 链接 url 里指定 useSSL=false。 链接 url 中显式指定时区，增加 serverTimezone=Asia/Shanghai。 兼容性问题 com.mysql.jdbc.exceptions.jdbc4 在 MySQL Connector 8 中不存在。
将 mysql-connector-java 版本，升级到 8.0 后，如果项目中有使用 mysql 的 Exception 类，编译时会收到以下错误
error: package com.mysql.jdbc.exceptions.jdbc4 does not exist [ERROR] import com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException; [ERROR] import com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException; MySQL 在 8.0 版本重用了现有的 java.sql 异常类，取消了 exceptions.jdbc4 的异常类，整改的异常映射关系如下。
5.7 版本异常类 8.0 版本异常类 com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException java.sql.SQLSyntaxErrorException com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException java.sql.SQLIntegrityConstraintViolationException com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException java.sql.SQLTransactionRollbackException 数据库关键字扩充问题。
在适配 MySQL 8.0 的时候遇到如下报错。</description></item><item><title>MySQL大文件导入优化</title><link>https://l10178.github.io/bits-pieces/devops/mysql-large-import/</link><pubDate>Wed, 29 Dec 2021 23:54:37 +0800</pubDate><guid>https://l10178.github.io/bits-pieces/devops/mysql-large-import/</guid><description>项目中需要根据SQL文件导入数据，文件大约20G，正常导入约需要2小时，如何加快导入速度。
如果一个SQL文件只有一个表的数据，可以直接使用mysql load data infile 语法，速度比较快。
我们是一个SQL文件包含了很多表，导入过程经过如下设置，20G大约需要40分钟。
# 进入mysql mysql -u root -p # 创建数据库（如果已经有数据库忽略此步骤） CREATE DATABASE 数据库名; # 设置参数 set sql_log_bin=OFF;//关闭日志 set autocommit=0;//关闭autocommit自动提交模式 0是关闭 1 是开启（默认） set global max_allowed_packet = 20 *1024* 1024 * 1024; # 使用数据库 use 数据库名; # 开启事务 START TRANSACTION; # 导入SQL文件并COMMIT（因为导入比较耗时，导入和COMMIT一行命令） source 文件的路径; COMMIT;</description></item><item><title>Windows提权 + 设置环境变量</title><link>https://l10178.github.io/bits-pieces/windows/takeown/</link><pubDate>Sat, 25 Sep 2021 10:54:37 +0800</pubDate><guid>https://l10178.github.io/bits-pieces/windows/takeown/</guid><description>背景：公司 Windows 办公机受域控安全策略限制，部分文件无权修改，另外开发常用的设置系统环境变量也变灰无法设置。此问题解决方式如下。
提升文件权限 点击 Windows + X 快捷键 – 选择「命令提示符（管理员）。
在 CDM 窗口中执行如下命令。
takeown /f C:\要修复的文件路径 在拿到文件所有权后，还需要使用如下命令获取文件的完全控制权限。
icacls C:\要修复的文件路径 /Grant Administrators:F 命令行设置环境变量 Windows 下命令行设置环境变量，方式为 setx 变量名 变量值，变量值带空格等特殊符号的，用引号引起来。
# 通过命令行设置 Java Home setx JAVA_HOME &amp;#34;C:\Program Files\Java\jdk-11.0.2&amp;#34; # 设置 GO Path setx GOPATH &amp;#34;D:\workspace\go&amp;#34;</description></item><item><title>备考 CKA 过程，CKA 真题</title><link>https://l10178.github.io/bits-pieces/kubernetes/cka/</link><pubDate>Tue, 01 Jun 2021 23:54:37 +0800</pubDate><guid>https://l10178.github.io/bits-pieces/kubernetes/cka/</guid><description>备考 CKA （Certified Kubernetes Administrator）过程，心得，遇见问题，CKA 真题。
备考环境 备考使用的系统和软件版本如下。
Ubuntu：20.04 Focal Fossa Kubernetes：1.20.7 kubeadm：1.20.7 安装和使用问题记录 kubeadm 安装问题 安装 kubeadm，国内安装使用阿里镜像源。
$ cat /etc/apt/sources.list.d/kubernetes.list deb https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main 踩坑：因为使用的是 ubuntu 20.04，代号 focal，专门去各个代理镜像源找kubernetes-focal都没有找到，后来发现 google 官方根本没发布对应的版本，只有kubernetes-xenial， k8s 官方文档里 ubuntu 也是用的这一个版本。可以用，就用他吧。
kubeadm init 时指定使用阿里镜像源（解决国内连不上 k8s.gcr.io 的问题）、指定版本号(安装考试对应的版本，不一定是最新版本)。
通过指定--image-repository，不需要手动下载镜像重新打 tag，kubeadm 自动使用指定的 repository。
kubeadm init --image-repository=registry.aliyuncs.com/google_containers \ --pod-network-cidr=10.244.0.0/16 \ --kubernetes-version=v1.20.7 解决 scheduler Unhealthy，controller-manager Unhealthy 第一次安装完成后通过 kubectl get cs命令，发现 scheduler Unhealthy，controller-manager Unhealthy。
$ kubectl get cs NAME STATUS MESSAGE scheduler Unhealthy Get &amp;#34;http://127.</description></item><item><title>History入门</title><link>https://l10178.github.io/bits-pieces/linux/history/</link><pubDate>Fri, 29 Jan 2021 23:54:37 +0800</pubDate><guid>https://l10178.github.io/bits-pieces/linux/history/</guid><description>Linux 下 history 命令，用好历史命令提高工作效率。
搜索历史命令 快捷键 Ctrl + r
非常建议你使用这个命令, 因为当你曾经输过一个很长的命令之后, 当你再次想输入这个命令的时候, 你就可以按下这个快捷键, 然后键入那条长命令的关键词, 然后就会显示出含有那个关键词的命令, 每次按下这个键都会再往上搜一个。可以找个机器实际体会下，确实很常用。
重复上一次的命令 向上的方向键。上下键翻看历史命令，翻到想执行的命令回车。
两个叹号: ！！
还有这个：！-1
快捷键：Ctrl+p 或 Ctrl+n，向上和向下翻看历史命令，和上下键效果一样。
从历史记录中执行某个命令 还是沿袭上一个中的 !-n 模式, 其中 n 是一个编号。如下示例，执行了编号为 4 的命令。
1 service network restart 2 exit 3 id 4 cat /etc/redhat-release # !4 cat /etc/redhat-release 执行曾经的命令中特定开头的 假设你的部分历史命令如下:
1721 find . -type f 那么, 怎样重复执行 1721 条呢? 除了利用 !-1721 这么麻烦的方法，我们还可以用 !f 这样的姿势。因为开头的 f 是离着最后一条命令最近的, 所以 !f 就执行了它。
清空历史记录 history -c 在历史记录中显示时间 我们可以用 HISTTIMEFORMAT 这个变量来定义显示历史记录时的时间参数:</description></item><item><title>Shell 编程实用句式</title><link>https://l10178.github.io/bits-pieces/linux/shell-coding/</link><pubDate>Fri, 29 Jan 2021 23:54:37 +0800</pubDate><guid>https://l10178.github.io/bits-pieces/linux/shell-coding/</guid><description>选婿。
#!/usr/bin/env bash #!/usr/bin/bash 检查是否以 root 用户执行。
# check if run as root user if [[ `id -u` -ne 0 ]]; then echo &amp;#34;You need root privileges to run this script.&amp;#34; fi 获取正在执行脚本的绝对路径，注意直接用 $0 或 pwd 获取的可能都不要你想要的。
current_dir=$(cd `dirname $0`;pwd) 为当前目录包含子目录下所有 .sh 文件增加可执行权限。
chmod +x `find . -name &amp;#39;*.sh&amp;#39;` 将提示信息显示到终端（控制台），同时也写入到文件里。
log_file=/var/log/test.log echo &amp;#34;This line will echo to console and also write to log file.&amp;#34; | tee -a ${log_file} 类似于 Java properties 中 key=value 形式的字符串，取 key 和 value 的值。</description></item><item><title>tcpdump</title><link>https://l10178.github.io/bits-pieces/linux/tcpdump/</link><pubDate>Fri, 29 Jan 2021 23:54:37 +0800</pubDate><guid>https://l10178.github.io/bits-pieces/linux/tcpdump/</guid><description>tcpdump 捕捉网卡eth0流量，并存入到out.pcap文件中。
sudo tcpdump -vv -s0 -i eth0 -w out.pcap</description></item><item><title>TL;DR</title><link>https://l10178.github.io/bits-pieces/kubernetes/tldr/</link><pubDate>Fri, 29 Jan 2021 23:54:37 +0800</pubDate><guid>https://l10178.github.io/bits-pieces/kubernetes/tldr/</guid><description>复制&amp;ndash;粘贴，这就是生活。
复制 secret 到另一个 namespace。
kubectl get secret mys --namespace=na -oyaml | grep -v &amp;#39;^\s*namespace:\s&amp;#39; | kubectl apply --namespace=nb -f - 批量删除 pod。
kubectl get pods --all-namespaces | grep Evicted | awk &amp;#39;{print $2 &amp;#34; --namespace=&amp;#34; $1}&amp;#39; | xargs kubectl delete pod # Delete by label kubectl delete pod -n idaas-book -l app.kubernetes.io/name=idaas-book 密钥解密。
kubectl get secret my-creds -n mysql -o jsonpath=&amp;#34;{.data.ADMIN_PASSWORD}&amp;#34; | base64 --decode Docker 保存和导入镜像。
# save image(s) docker save image:tag image2:tag | gzip &amp;gt;xxx.</description></item><item><title>文件压缩解压</title><link>https://l10178.github.io/bits-pieces/linux/tar.gz/</link><pubDate>Fri, 29 Jan 2021 23:54:37 +0800</pubDate><guid>https://l10178.github.io/bits-pieces/linux/tar.gz/</guid><description>常用文件格式 .tar：tar 其实打包（或翻译为归档）文件，本身并没有压缩。在 Linux 里 man tar 可以看到它的描述也是“manipulate tape archives”（tar 最初被用来在磁带上创建档案，现在，用户可以在任何设备上创建档案，只是它的描述还没有改）。
.gz：gzip 是 GNU 组织开发的一个压缩程序，.gz 结尾的文件就是 gzip 压缩的结果。
.bz2：bzip2 是一个压缩能力更强的压缩程序，.bz2 结尾的文件就是 bzip2 压缩的结果。
.Z：compress 也是一个压缩程序。.Z 结尾的文件就是 compress 压缩的结果。
.zip：使用 zip 软件压缩的文件。
.tar.gz、.tar.bz2、.tar.xz 等可以理解为打包+压缩的效果，用软件解压可以发现比.gz 多了一层包。gzip 和 bzip2，不能同时压缩多个文件，tar 相当于开个挂加上同时压缩的特效，tar 先归档为一个大文件，而归档为大文件的速度是很快的，测试了一下几乎可以忽略不计。
除了这些格式外，常见的 deb、exe、msi、rpm、dmg、iso 等安装软件，其实都是经过压缩的，一般情况下没有必要再压缩。而 rar 基本认为是 Windows 平台专属的压缩算法了，各个 Linux 发行版都不自带 rar 压缩解压缩软件，所以可以看到很多软件发行的格式都是 .tar.gz 或 .zip。
解压缩 根据文件名后缀自行选择解压缩命令。
tar -xf test.tar gzip -d test.gz gunzip test.gz # -C 直接解压到指定目录 tar -xzf test.tar.gz -C /home bzip2 -d test.</description></item><item><title>PNG图片批量压缩</title><link>https://l10178.github.io/bits-pieces/linux/pngquant/</link><pubDate>Mon, 14 Dec 2020 23:54:37 +0800</pubDate><guid>https://l10178.github.io/bits-pieces/linux/pngquant/</guid><description>使用 pngquant 命令行批量压缩 PNG 图片。
pngquant 压缩当前目录下全部 PNG 文件，并且默认全覆盖已有。
for file in $(ls *.png) do pngquant $file --force --output $file done</description></item><item><title>数据库事务控制</title><link>https://l10178.github.io/bits-pieces/linux/transaction/</link><pubDate>Mon, 14 Dec 2020 23:54:37 +0800</pubDate><guid>https://l10178.github.io/bits-pieces/linux/transaction/</guid><description>数据库事务总结，主要包括数据库事务 ACID 属性介绍、数据库并发问题总结、事务传播行为和隔离级别。
概念 事务（Transaction）是并发控制的基本单位。它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。标准定义：指作为单个逻辑工作单元执行的一系列操作，而这些逻辑工作单元需要具有原子性， 一致性，隔离性和持久性四个属性，统称为 ACID 特性。
Atomic（原子性） 事务中包含的操作被看做一个不可分割的逻辑单元，这个逻辑单元中的操作要么全部成功，要么全部失败。
Consistency（一致性） 事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。只有合法的数据可以被写入数据库，否则事务应该将其回滚到最初状态。关于数据库一致性，更专业的解释请参考专业的书籍。
Isolation（隔离性） 事务允许多个用户对同一个数据进行并发访问，而不破坏数据的正确性和完整性。同时，并行事务的修改必须与其他并行事务的修改相互独立。
Durability（持久性） 事务提交后，对系统的影响是永久的。简单理解就是写进去了，不会因为时间、系统环境，关机重启等变化而变化。
数据库并发问题 数据库是共享资源，通常有许多个事务同时在运行。当多个事务并发地存取数据库时就会产生同时读取和（或）修改同一数据的情况。若对并发操作不加控制就可能会存取和存储不正确的数据，破坏数据库的一致性。所以数据库管理系统必须提供并发控制机制。
并发操作一般可能带来以下几种问题。为说明问题，先来准备一个例子，假设现在有一个账户表 TBL_BANK_ACCOUNT。
CREATE TABLE TBL_BANK_ACCOUNT（ AccountId CHAR(4) NOT NULL, -- 银行账号 Username NVARCHAR(63) NOT NULL, -- 用户名 Balance BIGINT NOT NULL -- 余额 ) INSERT INTO TBL_BANK_ACCOUNT VALUES (&amp;#39;9555&amp;#39;, &amp;#39;小明&amp;#39;, 1000) -- 北京分行账号 INSERT INTO dbo.BankAccount VALUES (&amp;#39;9556&amp;#39;, &amp;#39;小明&amp;#39;, 2000) -- 上海分行账号 脏读（Dirty reads） 一个事务读到另一个事务未提交的更新数据。
事务 1 取款事务 事务 2 工资转账事务 开始事务 开始事务 查询余额 1000 元 取出 100 变为 900 查询余额为 900 异常发生，事务回滚，余额恢复为 1000 汇入工资 2000 元，余额为 2900 提交事务，最终余额 2900，损失了 100 不可重复读（Non-Repeatable Reads） 在同一个事务内，读取表中的某一行记录，多次读取的结果不同。与幻读区别的重点在于修改，同样的条件，已经读取过的数据，再次读取出来和上一次的值不一样。</description></item><item><title/><link>https://l10178.github.io/bits-pieces/linux/regular-expressions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://l10178.github.io/bits-pieces/linux/regular-expressions/</guid><description>正则表达式从入门到放弃 首先来看几个问题：
假设有一个字符串“a b c”(中间是一个空格)，想实现按空格分割成一个数组[&amp;ldquo;a&amp;rdquo;,&amp;ldquo;b&amp;rdquo;,&amp;ldquo;c&amp;rdquo;]，用 Java 或 JavaScript 代码如何实现。 原始数组改成&amp;quot;a b c&amp;quot;(中间是 N 个空格)，仍分割成数组[&amp;ldquo;a&amp;rdquo;,&amp;ldquo;b&amp;rdquo;,&amp;ldquo;c&amp;rdquo;]，如何实现。 @Test public void testSplit() { String dotStr = &amp;#34;a.b.c&amp;#34;; assertEquals(dotStr.split(&amp;#34;.&amp;#34;).length, 0); assertEquals(dotStr.split(&amp;#34;\\.&amp;#34;).length, 3); String spaceStr=&amp;#34;a b c&amp;#34;;//a与b之间两个空格,b与c之间一个空格 assertEquals(spaceStr.split(&amp;#34; &amp;#34;).length, 4);//一个空格 assertEquals(spaceStr.split(&amp;#34; +&amp;#34;).length, 3);//一个或多个空格 assertEquals(&amp;#34;a b c&amp;#34;.split(&amp;#34; +&amp;#34;).length, 3);//一个或多个空格 assertEquals(&amp;#34;a b c&amp;#34;.split(&amp;#34; +&amp;#34;).length, 3);//一个或多个空格 //顺便提一句,与正则无关,注意下面这个结果,这是Java的split方法自己处理的 assertEquals(&amp;#34;a b c &amp;#34;.split(&amp;#34; &amp;#34;).length, 3);//split会去除最后为空的结果 assertEquals(&amp;#34; a b c&amp;#34;.split(&amp;#34; &amp;#34;).length, 4);//split不会去除前面为空的结果 } 以上就是一个正则的简单应用，其实平时工作中除了编程我们也会经常用到正则，比如搜索所有 Word 文档（*.doc）,在文本编辑器中搜索和替换文字等等。正则表达式经过数年的发展，已经逐渐从模糊而深奥的数学概念，发展成为在计算机各类工具和软件包应用中的主要功能，成为人们工作中的一个利器。
什么是正则表达式 正则表达式（Regular Expression，regex、regexp，以下简称正则）是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。
完整的正则表达式由两种字符构成，特殊字符（又译元字符）和普通文字。如果把正则表达式想象成普通的语言，普通文字相当于语言中的单词，而元字符相当于语法。就像一门语言一样，正则是烦琐而强大的，学会之后的应用会让你除了提高效率外，会给你带来绝对的成就感。只要坚持去学，一定会放弃的。
正则引擎 引擎就相当于语言的编译器，解释器，用来对正则进行语法分析。不同的引擎决定了某个正则能否匹配、在何处匹配，以及匹配成功或报告失败的速度，另外知道正则表达式引擎是如何工作的有助于理解为何某个正则表达式在一个平台好用，换个平台就不好使了。</description></item></channel></rss>