"use strict";(function(){const t={};t.doc={id:"id",field:["title","content"],store:["title","href"]};const e=FlexSearch.create(t);window.geekdocSearchIndex=e,e.add({id:0,href:"/bits-pieces/java/spring-boot-micrometer/",title:"Spring Boot 使用 Micrometer 集成 Prometheus 监控",content:`主要内容：
Micrometer 介绍。 业务如何自定义指标，实现方式和规范。 Micrometer 介绍 Micrometer 为 Java 平台上的性能数据收集提供了一个通用的 API，它提供了多种度量指标类型（Timers、Guauges、Counters 等），同时支持接入不同的监控系统，例如 Influxdb、Graphite、Prometheus、OTLP 等。
从 Spring Boot 2.x 开始使用 Micrometer 作为默认的监控门面接口， Think SLF4J, but for observability 。
Micrometer 核心概念 MeterRegistry
内存注册表 (SimpleMeterRegistry): 在内存中保存每一个 Meter（指标）的最新值，并且不会将数据导出到任何地方。 组合注册表 (CompositeMeterRegistry): 可以添加多个注册表，用于将各个注册表组合起来，可以同时将指标发布到多个监控系统。 普罗米修斯注册表 (PrometheusMeterRegistry): 当使用普罗米修斯监控时，引入 micrometer-registry-prometheus 依赖时会提供此种收集器，用于将指标数据转换为普罗米修斯识别的格式和导出数据等功能。 Meter（指标）
监控数据的整个过程都是围绕着 Meter（指标）, 通过一个一个的 Meter（指标）数据来进行观察应用的状态。常用的指标如：
Counter（计数器）: 单一计数指标，允许按固定数量递增，用来统计无上限数据。 Gauge（仪表盘）: 用于统计有上限可增可减的数据。 Timer（计时器）: 用于测量短时延迟和事件频率。 Tag（标签） Mircrometer 通过 Tag（标签）实现了多维度的度量数据收集，通过 Tag 的命名可以推断出其指向的数据代表什么维度或是什么类型的度量指标。
当前实现方式和要求 总体架构： Spring Boot Actuator + Micrometer + Prometheus。
总体实现步骤如下：
Spring Boot Actuator 放开 prometheus http 访问。 创建 Prometheus ServiceMonitor，从 /actuator/prometheus path 采集指标，如果涉及多个 war 合并部署到一个 tomcat 的，从多个 path 采集。 apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: labels: app.kubernetes.io/component: metrics release: eye2 name: eye-consumer namespace: test spec: endpoints: - interval: 30s honorLabels: true path: /client-log2es/actuator/prometheus port: http - interval: 30s honorLabels: true path: /gateway-log2es/actuator/prometheus port: http jobLabel: eye-consumer selector: matchLabels: app: eye-consumer 注意事项：
原有的 jmx_exporter agent 在 Spring Boot 应用里逐渐下线。 单个 Spring Boot 应用，Actuator 使用独立的 8081 端口，业务服务使用 8080 端口。如果是 war 形式合并部署到 Tomcat 的都使用 8080 端口。 自定义 Metrics 指标 在 Spring Boot 中实现自定义指标非常简单，几种方式举例如下。
像使用 slf4j 一样，使用 io.micrometer.core.instrument.Metrics 静态方式初始化一个计数器。 使用 @Timed @Counted 注解。注意注解方式必须等方法调用后才能生成指标。而静态方法形式 io.micrometer.core.instrument.Metrics.counter立即就生成指标只是值为 0。另外注意 Spring 注解不支持 private、default 级别方法。 import io.micrometer.core.annotation.Counted; import io.micrometer.core.instrument.Counter; import io.micrometer.core.instrument.Metrics; import org.springframework.stereotype.Service; @Service public class MicrometerSampleService { /** * 方式 1：像使用 slf4j 一样，使用 \`io.micrometer.core.instrument.Metrics\`静态方式初始化一个计数器 */ private static final Counter failure = Metrics.counter(&#34;fs.sms.send&#34;, &#34;result&#34;, &#34;failed&#34;); private void sendSms() { try { // do something } catch (Exception e) { failure.increment(); } } /** * 方式 2：使用注解的方式，注意需要引入 spring-boot-starter-aop 依赖 */ @Counted(value = &#34;fs.sms.send&#34;, extraTags = {&#34;provider&#34;, &#34;huawei&#34;}) public void sendByHuawei() { this.sendSms(); } @Counted(value = &#34;fs.sms.send&#34;, extraTags = {&#34;provider&#34;, &#34;ali&#34;}) public void sendByAli() { this.sendSms(); } } Spring Boot 无法直接使用 @Timed @Counted 注解，需要引入切面支持，需要引入 spring-boot-starter-aop 依赖。
@Configuration public class MicrometerAspectConfiguration { @Bean public CountedAspect countedAspect(MeterRegistry registry) { return new CountedAspect(registry); } @Bean public TimedAspect timedAspect(MeterRegistry registry) { return new TimedAspect(registry); } } 为了方便大家使用，已经在我们的 starter 里自动注入了以上 Bean，大家只需要引入我们自定义的 starter。
&lt;dependency&gt; &lt;groupId&gt;com.fxiaoke.boot&lt;/groupId&gt; &lt;artifactId&gt;metrics-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; 自定义指标规范和要求 指标和 Tag 命名约定使用英语逗号分隔，全小写。 指标命名建议以 公司固定开头。业务名。动作名 为模板，避免与开源或其他项目组冲突。 注意 Tag values 不能为空，建议是可枚举的某些固定类型便于统计。 使用注解@Timed @Counted会默认增加 method、class、result、exception 这几个 Tag，注意不要与之冲突。 公司和开源默认 Tag 如下，会被强制覆盖，业务不要自己定义。 namespace、application、service、container、pod、instance、job、endpoint、id 。 注意别引错了类，有很多同名的类，使用 io.micrometer.core 包下的类。 `}),e.add({id:1,href:"/bits-pieces/kubernetes/pid/",title:"容器进程数限制",content:`问题描述：
一个 Java 应用跑在 K8S 容器内，Pod 内只有 Java 这一个进程。应用跑了一段时间后，开始出现以下错误。
Exception in thread &#34;slow-fetch-15&#34; java.lang.OutOfMemoryError: unable to create new native thread 428 at java.lang.Thread.start0(Native Method) 429 at java.lang.Thread.start(Thread.java:719) 430 at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957) 431 at java.util.concurrent.ThreadPoolExecutor.processWorkerExit(ThreadPoolExecutor.java:1025) 432 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167) 433 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) 进入 Pod 内，尝试执行任何操作，又会出现 unable to start container process 错误。
一开始怀疑是内存不足，调大了内存，同时也缩小了 Java 的 xss， 都不起作用。
真实原因： K8S 容器限制了 PID 数，无法创建新的线程，在 Pod 内 cat /sys/fs/cgroup/pids/pids.max 发现是 1024。
关于 K8S pod pid limit， 可参考此资料: https://kubernetes.io/zh-cn/docs/concepts/policy/pid-limiting/.
但是，PID 为什么会超呢，Pod 内只有一个 Java 进程，PID 数不应该是 1 吗，这个 PID 限制为什么影响了线程。
简单来讲，在 Linux 中线程其实是通过轻量级进程实现的，也就是 LWP(light weight process)，因此在 Linux 中每个线程都是一个进程，都拥有一个 PID，换句话说，操作系统原理中的线程，对应的其实是 Linux 中的进程(即 LWP)，因此 Linux 内核中的 PID 对应的其实是原理中的 TID。
在 Pod 内通过 top -p pid -H 查看，可以看到第一列每个线程都有一个 PID。
PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 101 root 20 0 8622220 5.1g 15640 S 0.3 8.1 0:16.29 VM Thread 112 root 20 0 8622220 5.1g 15640 S 0.3 8.1 0:46.13 C2 CompilerThre 113 root 20 0 8622220 5.1g 15640 S 0.3 8.1 0:39.62 C1 CompilerThre 846 root 20 0 8622220 5.1g 15640 S 0.3 8.1 0:00.64 NettyClientSele 850 root 20 0 8622220 5.1g 15640 S 0.3 8.1 0:00.54 NettyClientWork 1 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:00.27 java 89 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:00.99 java 90 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:03.29 java 91 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:03.27 java 92 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:03.26 java 93 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:03.30 java 94 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:01.43 java 95 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:00.11 java 96 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:00.12 java 97 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:00.16 java 98 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:00.31 java 99 root 20 0 8622220 5.1g 15640 S 0.0 8.1 0:00.32 java `}),e.add({id:2,href:"/bits-pieces/linux/git/",title:"Git常用配置",content:`Git 多用户配置 Git 给不同目录配置不同的 config，比如区分个人开发账号和公司开发账号。
为账户 B 准备一个单独的配置文件，比如： ~/.gitconfig-b，内容根据需要定义。
[user] name = userb-name email = userb-email@test.com 修改 ~/.gitconfig 文件，增加以下配置，引用上面创建的配置文件，注意用绝对路径，并且路径以 / 结尾。
[includeIf &#34;gitdir:/project/path-b/&#34;] path = /Users/xxxx/.gitconfig-b 保存后，在 /project/path-b/ 下新的仓库都会以 .gitconfig-b 中的用户名和邮箱提交了。
`}),e.add({id:3,href:"/bits-pieces/kubernetes/envoy/",title:"Envoy生产配置最佳实践",content:`Envoy 监控指标 Envoy 将其指标分为以下主要类别：
Downstream：与进入代理的连接和请求相关的指标。它们由 listener、HTTP connection manager(HCM)、TCP proxy filter 等产生。 Upstream：与传出连接和代理发出的请求相关的指标。它们由 connection pool、router filter、tcp proxy filter 等产生。 Server：描述 Envoy 内部状态的指标。其中包括正常运行时间或分配的内存等指标。 Envoy 发出三种指标数据类型：
Counter(Counters)：无符号整数，只会增加而不会减少。例如，总请求。 仪表(Gauges)：增加和减少的无符号整数。例如，当前活动的请求。 Histograms(Histograms)：作为指标流的一部分的无符号整数，然后由收集器聚合以最终产生汇总的百分位值(percentile，即平常说的 P99/P50/Pxx)。例如，Upsteam 响应时间。 在 Envoy 的内部实现中，Counters 和 Gauges 被分批并定期刷新以提高性能，Histograms 在接收时写入。
从指标的产出地点来划分，可以分为：
cluster manager: 面向 upstream 的 L3/L4/L7 层指标。 http connection manager(HCM)： 面向 upstream &amp; downstream 的 L7 层指标。 listeners: 面向 downstream 的 L3/L4 层指标。 server：全局。 Envoy 通过 admin 端口放开了 prometheus 格式的监控指标，可以通过 admin 接口快速查看当前已支持的指标：http://127.0.0.1:9901/stats/prometheus，其中 9901 是 admin 端口。
`}),e.add({id:4,href:"/bits-pieces/java/jvm/",title:"Java进程内存分析",content:`故事背景：
一个 K8S Pod，里面只有一个 Java 进程，K8S request 和 limit memory 都是 2G，Java 进程核心参数包括：-XX:+UseZGC -Xmx1024m -Xms768m -XX:SoftMaxHeapSize=512m。
服务启动一段时间后，查看 Grafana 监控数据，Pod 内存使用量约 1.5G，JVM 内存使用量约 500M，通过 jvm dump 分析没有任何大对象，运行三五天后出现 ContainerOOM。
首先区分下 ContainerOOM 和 JvmOOM，ContainerOOM 是 Pod 内存不够，Java 向操作系统申请内存时内存不足导致。
问题来了：
Pod 2G 内存，JVM 设置了 Xmx 1G，已经预留了 1G 内存，为什么还会 ContainerOOM，这预留的 1G 内存被谁吃了。 正常情况下（无 ContainerOOM），Grafana 看到的监控数据，Pod 内存使用量 1.5G， JVM 内存使用量 500M，差别为什么这么大。 Grafana 看到的监控数据，内存使用量、提交量各是什么意思，这些值是怎么算出来的，和 Pod 进程中如何对应，为什么提交量一直居高不小。 Grafana 监控图。
统计指标 Pod 内存使用量统计的指标是 container_memory_working_set_bytes：
container_memory_usage_bytes = container_memory_rss + container_memory_cache + kernel memory container_memory_working_set_bytes = container_memory_usage_bytes - total_inactive_file（未激活的匿名缓存页） container_memory_working_set_bytes 是容器真实使用的内存量，也是资源限制 limit 时的 OOM 判断依据。
另外注意 cgroup 版本差异： container_memory_cache reflects cache (cgroup v1) or file (cgroup v2) entry in memory.stat.
JVM 内存使用量统计的指标是 jvm_memory_bytes_used： heap、non-heap 以及其他 真实用量总和。下面解释其他。
对比一下 top 命令，使用 top 命令看一下 Java 进程真正占了多少。
top -p $(pgrep java) # 注意下面的数据和截图不是同一时间的 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 7 root 20 0 58.2g 1.6g 1.0g S 17.3 2.3 659:42.46 java VIRT：virtual memory usage 虚拟内存
进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等 假如进程申请 100m 的内存，但实际只使用了 10m，那么它会增长 100m，而不是实际的使用量 RES：resident memory usage 常驻内存
进程当前使用的内存大小，但不包括被换出到交换区的部分 包含其他进程的共享 如果申请 100m 的内存，实际使用 10m，它只增长 10m，与 VIRT 相反 关于库占用内存的情况，它只统计加载的库文件所占内存大小 SHR：shared memory 共享内存
除了自身进程的共享内存，也包括其他进程的共享内存 虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小 计算某个进程所占的物理内存大小公式：RES – SHR。（JVM 的内存使用量等于 RES-SHR） container_memory_working_set_bytes 与 Top RES 相等吗。
为什么 container_memory_working_set_bytes 大于 top RES:
因为 container_memory_working_set_bytes 包含 container_memory_cache，这涉及到 Linux 缓存机制，延伸阅读：https://zhuanlan.zhihu.com/p/449630026。遇到这种场景一般都是文件操作较多，可优先排除文件类操作。
为什么 container_memory_working_set_bytes 小于 top RES:
主要还是算法和数据来源不一样，top 的 RES=Code + Data，有些服务 Data 比较大。 当然实际测试会发现 RES!=Code + Data ，延伸阅读：https://liam.page/2020/07/17/memory-stat-in-TOP/
另外可能看到的现象，top、granfana、docker stats、JMX 看到的使用量怎么都不一样，都是因为他们统计的维度不一样。
所以通过 top 命令看到的数据不一定是真实的，container_memory_working_set_bytes 指标来自 cadvisor，cadvisor 数据来源 cgroup，可以查看以下文件获取真实的内存情况。
# 线上老版本，cgroup v1 ll /sys/fs/cgroup/memory/ total 0 drwxr-xr-x. 2 root root 0 Dec 24 19:22 ./ dr-xr-xr-x. 13 root root 340 Dec 24 19:22 ../ -rw-r--r--. 1 root root 0 Dec 24 19:22 cgroup.clone_children --w--w--w-. 1 root root 0 Dec 24 19:22 cgroup.event_control -rw-r--r--. 1 root root 0 Dec 24 19:22 cgroup.procs -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.failcnt --w-------. 1 root root 0 Dec 24 19:22 memory.force_empty -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.failcnt -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.limit_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.max_usage_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.slabinfo -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.tcp.failcnt -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.tcp.limit_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.tcp.max_usage_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.tcp.usage_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.usage_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.limit_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.max_usage_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.memsw.failcnt -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.memsw.limit_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.memsw.max_usage_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.memsw.usage_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.move_charge_at_immigrate -r--r--r--. 1 root root 0 Dec 24 19:22 memory.numa_stat -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.oom_control ----------. 1 root root 0 Dec 24 19:22 memory.pressure_level -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.soft_limit_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.stat -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.swappiness -r--r--r--. 1 root root 0 Dec 24 19:22 memory.usage_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.use_hierarchy -rw-r--r--. 1 root root 0 Dec 24 19:22 notify_on_release -rw-r--r--. 1 root root 0 Dec 24 19:22 tasks # 线下新版本，cgroup v2 ll /sys/fs/cgroup/memory.* -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.current -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.events -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.events.local -rw-r--r-- 1 root root 0 Jan 7 11:50 /sys/fs/cgroup/memory.high -rw-r--r-- 1 root root 0 Jan 7 11:50 /sys/fs/cgroup/memory.low -rw-r--r-- 1 root root 0 Jan 7 11:50 /sys/fs/cgroup/memory.max -rw-r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.min -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.numa_stat -rw-r--r-- 1 root root 0 Jan 7 11:50 /sys/fs/cgroup/memory.oom.group -rw-r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.pressure -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.stat -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.swap.current -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.swap.events -rw-r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.swap.high -rw-r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.swap.max JVM 关于使用量和提交量的解释。
Used Size：The used space is the amount of memory that is currently occupied by Java objects. 当前实际真的用着的内存，每个 bit 都对应了有值的。
Committed Size：The committed size is the amount of memory guaranteed to be available for use by the Java virtual machine.
操作系统向 JVM 保证可用的内存大小，或者说 JVM 向操作系统已经要的内存。站在操作系统的角度，就是已经分出去（占用）的内存，保证给 JVM 用了，其他进程不能用了。 由于操作系统的内存管理是惰性的，对于已申请的内存虽然会分配地址空间，但并不会直接占用物理内存，真正使用的时候才会映射到实际的物理内存，所以 committed &gt; res 也是很可能的。
Java 进程内存分析 Pod 的内存使用量 1.5G，都包含哪些。
kernel memory 为 0，Cache 约 1100M，rss 约 650M，inactive_file 约 200M。可以看到 Cache 比较大，因为这个服务比较特殊有很多文件操作。
# 这个数据和上面的1.5G不是同时的。 cat /sys/fs/cgroup/memory/memory.stat cache 1455861760 rss 685862912 rss_huge 337641472 mapped_file 504979456 swap 0 inactive_anon 805306368 active_anon 685817856 inactive_file 299671552 active_file 350883840 total_rss 685862912 total_rss_huge 337641472 total_mapped_file 504979456 total_inactive_file 299671552 total_active_file 350883840 # cgroup v2 变量变了 cat /sys/fs/cgroup/memory.stat anon 846118912 file 2321530880 kernel_stack 10895360 pagetables 15523840 percpu 0 sock 1212416 shmem 1933574144 file_mapped 1870290944 file_dirty 12288 file_writeback 0 swapcached 0 anon_thp 0 file_thp 0 shmem_thp 0 inactive_anon 2602876928 active_anon 176771072 inactive_file 188608512 active_file 199348224 unevictable 0 slab_reclaimable 11839688 slab_unreclaimable 7409400 slab 19249088 workingset_refault_anon 0 workingset_refault_file 318 workingset_activate_anon 0 workingset_activate_file 95 workingset_restore_anon 0 workingset_restore_file 0 workingset_nodereclaim 0 pgfault 2563565 pgmajfault 15 pgrefill 14672 pgscan 25468 pgsteal 25468 pgactivate 106436 pgdeactivate 14672 pglazyfree 0 pglazyfreed 0 thp_fault_alloc 0 thp_collapse_alloc 0 通过 Java 自带的 Native Memory Tracking 看下内存提交量。
# Java启动时先打开NativeMemoryTracking，默认是关闭的。注意不要在生产环境长期开启，有性能损失 java -XX:NativeMemoryTracking=detail -jar # 查看详情 jcmd $(pgrep java) VM.native_memory detail scale=MB 通过 Native Memory Tracking 追踪到的详情大致如下，关注其中每一项 committed 值。
Native Memory Tracking: (Omitting categories weighting less than 1MB) Total: reserved=68975MB, committed=1040MB - Java Heap (reserved=58944MB, committed=646MB) (mmap: reserved=58944MB, committed=646MB) - Class (reserved=1027MB, committed=15MB) (classes #19551) #加载类的个数 ( instance classes #18354, array classes #1197) (malloc=3MB #63653) (mmap: reserved=1024MB, committed=12MB) ( Metadata: ) ( reserved=96MB, committed=94MB) ( used=93MB) ( waste=0MB =0.40%) ( Class space:) ( reserved=1024MB, committed=12MB) ( used=11MB) ( waste=1MB =4.63%) - Thread (reserved=337MB, committed=37MB) (thread #335) #线程的个数 (stack: reserved=336MB, committed=36MB) (malloc=1MB #2018) - Code (reserved=248MB, committed=86MB) (malloc=6MB #24750) (mmap: reserved=242MB, committed=80MB) - GC (reserved=8243MB, committed=83MB) (malloc=19MB #45814) (mmap: reserved=8224MB, committed=64MB) - Compiler (reserved=3MB, committed=3MB) (malloc=3MB #2212) - Internal (reserved=7MB, committed=7MB) (malloc=7MB #31683) - Other (reserved=18MB, committed=18MB) (malloc=18MB #663) - Symbol (reserved=19MB, committed=19MB) (malloc=17MB #502325) (arena=2MB #1) - Native Memory Tracking (reserved=12MB, committed=12MB) (malloc=1MB #8073) (tracking overhead=11MB) - Shared class space (reserved=12MB, committed=12MB) (mmap: reserved=12MB, committed=12MB) - Module (reserved=1MB, committed=1MB) (malloc=1MB #4996) - Synchronization (reserved=1MB, committed=1MB) (malloc=1MB #2482) - Metaspace (reserved=97MB, committed=94MB) (malloc=1MB #662) (mmap: reserved=96MB, committed=94MB) - Object Monitors (reserved=8MB, committed=8MB) (malloc=8MB #39137) 一图解千愁，盗图。
Heap Heap 是 Java 进程中使用量最大的一部分内存，是最常遇到内存问题的部分，Java 也提供了很多相关工具来排查堆内存泄露问题，这里不详细展开。Heap 与 RSS 相关的几个重要 JVM 参数如下： Xms：Java Heap 初始内存大小。(目前我们用的百分比控制，MaxRAMPercentage) Xmx：Java Heap 的最大大小。(InitialRAMPercentage) XX:+UseAdaptiveSizePolicy：是否开启自适应大小策略。开启后，JVM 将动态判断是否调整 Heap size，来降低系统负载。
Metaspace Metaspace 主要包含方法的字节码，Class 对象，常量池。一般来说，记载的类越多，Metaspace 使用的内存越多。与 Metaspace 相关的 JVM 参数有: XX:MaxMetaspaceSize: 最大的 Metaspace 大小限制【默认无限制】 XX:MetaspaceSize=64M: 初始的 Metaspace 大小。如果 Metaspace 空间不足，将会触发 Full GC。 类空间占用评估，给两个数字可供参考：10K 个类约 90M，15K 个类约 100M。 什么时候回收：分配给一个类的空间，是归属于这个类的类加载器的，只有当这个类加载器卸载的时候，这个空间才会被释放。释放 Metaspace 的空间，并不意味着将这部分空间还给系统内存，这部分空间通常会被 JVM 保留下来。 扩展：参考资料中的Java Metaspace详解，这里完美解释 Metaspace、Compressed Class Space 等。
Thread NMT 中显示的 Thread 部分内存与线程数与 -Xss 参数成正比，一般来说 committed 内存等于 Xss*线程数 。
Code JIT 动态编译产生的 Code 占用的内存。这部分内存主要由-XX:ReservedCodeCacheSize 参数进行控制。
Internal Internal 包含命令行解析器使用的内存、JVMTI、PerfData 以及 Unsafe 分配的内存等等。 需要注意的是，Unsafe_AllocateMemory 分配的内存在 JDK11 之前，在 NMT 中都属于 Internal，但是在 JDK11 之后被 NMT 归属到 Other 中。
Symbol Symbol 为 JVM 中的符号表所使用的内存，HotSpot 中符号表主要有两种：SymbolTable 与 StringTable。 大家都知道 Java 的类在编译之后会生成 Constant pool 常量池，常量池中会有很多的字符串常量，HotSpot 出于节省内存的考虑，往往会将这些字符串常量作为一个 Symbol 对象存入一个 HashTable 的表结构中即 SymbolTable，如果该字符串可以在 SymbolTable 中 lookup（SymbolTable::lookup）到，那么就会重用该字符串，如果找不到才会创建新的 Symbol（SymbolTable::new_symbol）。 当然除了 SymbolTable，还有它的双胞胎兄弟 StringTable（StringTable 结构与 SymbolTable 基本是一致的，都是 HashTable 的结构），即我们常说的字符串常量池。平时做业务开发和 StringTable 打交道会更多一些，HotSpot 也是基于节省内存的考虑为我们提供了 StringTable，我们可以通过 String.intern 的方式将字符串放入 StringTable 中来重用字符串。
Native Memory Tracking Native Memory Tracking 使用的内存就是 JVM 进程开启 NMT 功能后，NMT 功能自身所申请的内存。
观察上面几个区域的分配，没有明显的异常。
NMT 追踪到的 是 Committed，不一定是 Used，NMT 和 cadvisor 没有找到必然的对应的关系。可以参考 RSS，cadvisor 追踪到 RSS 是 650M，JVM Used 是 500M，还有大约 150M 浮动到哪里去了。
因为 NMT 只能 Track JVM 自身的内存分配情况，比如：Heap 内存分配，direct byte buffer 等。无法追踪的情况主要包括：
使用 JNI 调用的一些第三方 native code 申请的内存，比如使用 System.Loadlibrary 加载的一些库。 标准的 Java Class Library，典型的，如文件流等相关操作（如：Files.list、ZipInputStream 和 DirectoryStream 等）。主要涉及到的调用是 Unsafe.allocateMemory 和 java.util.zip.Inflater.init(Native Method)。 怎么追踪 NMT 追踪不到的其他内存，目前是安装了 jemalloc 内存分析工具，他能追踪底层内存的分配情况输出报告。
通过 jemalloc 内存分析工具佐证了上面的结论，Unsafe.allocateMemory 和 java.util.zip.Inflater.init 占了 30%，基本吻合。
启动 arthas 查看下类调用栈，在 arthas 里执行以下命令：
# 先设置unsafe true options unsafe true # 这个没有 stack sun.misc.Unsafe allocateMemory # 这个有 stack jdk.internal.misc.Unsafe allocateMemory stack java.util.zip.Inflater inflate 通过上面的命令，能看到 MongoDB 和 netty 一直在申请使用内存。注意：早期的 mongodb client 确实有无法释放内存的 bug，但是在我们场景，长期观察会发现内存申请了逐渐释放了，没有持续增长。回到开头的 ContainerOOM 问题，可能一个原因是流量突增，MongoDB 申请了更多的内存导致 OOM，而不是因为内存不释放。
ts=2022-12-29 21:20:01;thread_name=ForkJoinPool.commonPool-worker-1;id=22;is_daemon=true;priority=1;TCCL=jdk.internal.loader.ClassLoaders$AppClassLoader@1d44bcfa @jdk.internal.misc.Unsafe.allocateMemory() at java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:125) at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:332) at sun.nio.ch.Util.getTemporaryDirectBuffer(Util.java:243) at sun.nio.ch.NioSocketImpl.tryWrite(NioSocketImpl.java:394) at sun.nio.ch.NioSocketImpl.implWrite(NioSocketImpl.java:413) at sun.nio.ch.NioSocketImpl.write(NioSocketImpl.java:440) at sun.nio.ch.NioSocketImpl$2.write(NioSocketImpl.java:826) at java.net.Socket$SocketOutputStream.write(Socket.java:1035) at com.mongodb.internal.connection.SocketStream.write(SocketStream.java:99) at com.mongodb.internal.connection.InternalStreamConnection.sendMessage(InternalStreamConnection.java:426) at com.mongodb.internal.connection.UsageTrackingInternalConnection.sendAndReceive(UsageTrackingInternalConnection.java:99) at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection.sendAndReceive(DefaultConnectionPool.java:444) ……………………………… at com.mongodb.MongoClientExt$1.execute(MongoClientExt.java:42) at com.facishare.oms.thirdpush.dao.MongoDao.save(MongoDao.java:31) ……………………………… 总结 Java 进程内存占用：Total=heap + non-heap + 上面说的这个其他。
jemalloc jemalloc 是一个比 glibc malloc 更高效的内存池技术，在 Facebook 公司被大量使用，在 FreeBSD 和 FireFox 项目中使用了 jemalloc 作为默认的内存管理器。使用 jemalloc 可以使程序的内存管理性能提升，减少内存碎片。
比如 Redis 内存分配默认使用的 jemalloc，早期版本安装 redis 是需要手动安装 jemalloc 的，现在 redis 应该是在编译期内置好了。
原来使用 jemalloc 是为了分析内存占用，通过 jemalloc 输出当前内存分配情况，或者通过 diff 分析前后内存差，大概能看出内存都分给睡了，占了多少，是否有内存无法释放的情况。
后来参考了这个文章，把 glibc 换成 jemalloc 带来性能提升，降低内存使用，决定一试。
how we’ve reduced memory usage without changing any code：https://blog.malt.engineering/java-in-k8s-how-weve-reduced-memory-usage-without-changing-any-code-cbef5d740ad
Decreasing RAM Usage by 40% Using jemalloc with Python &amp; Celery: https://zapier.com/engineering/celery-python-jemalloc/
一个服务，运行一周，观察效果。
使用 Jemalloc 之前： 使用 Jemalloc 之后（同时调低了 Pod 内存）： 注：以上结果未经生产长期检验。
内存交还给操作系统 注意：下面的操作，生产环境不建议这么干。
默认情况下，OpenJDK 不会主动向操作系统退还未用的内存（不严谨）。看第一张监控的图，会发现运行一段时间后，Pod 的内存使用量一直稳定在 80%&ndash;90%不再波动。
其实对于 Java 程序，浮动比较大的就是 heap 内存。其他区域 Code、Metaspace 基本稳定
# 执行命令获取当前heap情况 jhsdb jmap --heap --pid $(pgrep java) #以下为输出 Attaching to process ID 7, please wait... Debugger attached successfully. Server compiler detected. JVM version is 17.0.5+8-LTS using thread-local object allocation. ZGC with 4 thread(s) Heap Configuration: MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 1287651328 (1228.0MB) NewSize = 1363144 (1.2999954223632812MB) MaxNewSize = 17592186044415 MB OldSize = 5452592 (5.1999969482421875MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 22020096 (21.0MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB) Heap Usage: ZHeap used 310M, capacity 710M, max capacity 1228M Java 内存不交还，几种情况：
Xms 大于实际需要的内存，比如我们服务设置了 Xms768M，但是实际上只需要 256，高峰期也就 512，到不了 Xms 的值也就无所谓归还。 上面 jmap 的结果，可以看到 Java 默认的配置 MaxHeapFreeRatio=70，这个 70% Free 几乎很难达到。（另外注意 Xmx==Xms 的情况下这两个参数无效，因为他怎么扩缩都不会突破 Xms 和 Xmx 的限制）
MinHeapFreeRatio = 40 空闲堆空间的最小百分比，计算公式为：HeapFreeRatio =(CurrentFreeHeapSize/CurrentTotalHeapSize) * 100，值的区间为0到100，默认值为 40。如果HeapFreeRatio &lt; MinHeapFreeRatio，则需要进行堆扩容，扩容的时机应该在每次垃圾回收之后。 MaxHeapFreeRatio = 70 空闲堆空间的最大百分比，计算公式为：HeapFreeRatio =(CurrentFreeHeapSize/CurrentTotalHeapSize) * 100，值的区间为0到100，默认值为 70。如果HeapFreeRatio &gt; MaxHeapFreeRatio，则需要进行堆缩容，缩容的时机应该在每次垃圾回收之后。 对于 ZGC，默认是交还给操作系统的。可通过 -XX:+ZUncommit -XX:ZUncommitDelay=300 这两个参数控制（不再使用的内存最多延迟 300s 归还给 OS，线下环境可以改小点）。
经过调整后的服务，内存提交在 500&ndash;800M 之间浮动，不再是一条直线。
问题原因分析和调整 回到开头问题，通过上面分析，2G 内存，RSS 其实占用 600M，为什么最终还是 ContainerOOM 了。
kernel memory 为 0，排除 kernel 泄漏的原因。下面的参考资料里介绍了 kernel 泄露的两种场景。 Cache 很大，说明文件操作多。搜了一下代码，确实有很多 InputStream 调用没有显式关闭，而且有的 InputSteam Root 引用在 ThreadLocal 里，ThreadLocal 只 init 未 remove。 但是，ThreadLocal 的引用对象是线程池，池不回收，所以这部分可能会无法关闭，但是不会递增，但是 cache 也不能回收。 优化办法：ThreadLocal 中对象是线程安全的，无数据传递，直接干掉 ThreadLocal；显式关闭 InputStream。运行一周发现 cache 大约比优化前低 200&ndash;500M。 ThreadLocal 引起内存泄露是 Java 中很经典的一个场景，一定要特别注意。 一般场景下，Java 程序都是堆内存占用高，但是这个服务堆内存其实在 200-500M 之间浮动，我们给他分了 768M，从来没有到过这个值，所以调低 Xms。留出更多内存给 JNI 使用。 线下环境内存分配切换到 jemalloc，待长期观察效果。 经过上述调整以后： 线下环境 Pod 内存使用量由 1G 降到 600M 作用。线上环境内存使用量在 50%&ndash;80%之间根据流量大小浮动，原来是 85% 居高不小。
参考资料 Java 进程内存分布：https://cloud.tencent.com/developer/article/1666640
Java Metaspace 详解：https://www.javadoop.com/post/metaspace
how we’ve reduced memory usage without changing any code：https://blog.malt.engineering/java-in-k8s-how-weve-reduced-memory-usage-without-changing-any-code-cbef5d740ad
Spring Boot 引起的堆外内存泄漏排查及经验总结：https://tech.meituan.com/2019/01/03/spring-boot-native-memory-leak.html
Pod 进程内存缓存分析: https://zhuanlan.zhihu.com/p/449630026
Linux 内存中的 Cache 真的能被回收么: https://cloud.tencent.com/developer/article/1115557
Linux kernel memory 导致的 POD OOM killed: https://www.cnblogs.com/yannwang/p/13287963.html
cgroup 内存泄露问题: https://www.cnblogs.com/leffss/p/15019898.html
`}),e.add({id:5,href:"/bits-pieces/java/spring-start-site/",title:"Spring Start脚手架快速入门",content:`基于 start.spring.io 快速定制自己的脚手架，主要应用场景：
规范公司自己的 parent pom，增加特定的依赖项。 根据公司规范生成统一的包结构，统一命名。 根据约束增加特定代码或文件，比如根据公司要求统一 logback.xml 文件。 这篇文章的目的是如何快速开始，原理和详细配置官方文档已经很详细了。
快速开始 基本步骤：
对于 spring.initializr 我们没有定制的需求，直接引用官方的。 拷贝一份 start.spring.io，直接基于这个项目开发、部署、运行。以下都是关于如何修改 start.spring.io。 start.spring.io 主要关注两个模块：
start-client：前端页面，可以定制些自己的 logo、title 等。 start-site：是一个标准的 spring boot 项目，实际 run 起来的服务，引用了 start-client，直接 run 这个项目的 main 方法就能看到效果。 主要配置文件：start-site/src/main/resources/application.yml，通过修改这个配置文件可以达到的效果如下。
修改 start 启动时默认 group，把 com.example 改为公司自己的 group。
initializr: group-id: value: com.yourgroup 修改父 pom，使用公司自己的 pom。
initializr: env: maven: # use your parent pom parent: groupId: com.yourself artifactId: your-parent version: 1.0.0 # relativePath: ../pom.xml includeSpringBootBom: false 限定 Java 和 Spring Boot 版：修改 languages 和 bootVersions 即可。
增加公司自己的 starter，参考文件中例子增加即可。
核心扩展接口 ProjectContributor: 用于实现文件结构变化，比如加个文件夹，增加配置文件、代码片段等。 BuildCustomizer：动态修改 pom.xml，用于修改 maven/gradle 的 dependencies/repository/plugins 等。 更多自带定制接口参考：MainSourceCodeCustomizer, MainCompilationUnitCustomizer, MainApplicationTypeCustomizer, TestSourceCodeCustomizer, TestApplicationTypeCustomizer. 场景：生成默认的 logback-spring.xml。
import io.spring.initializr.generator.project.contributor.SingleResourceProjectContributor; /** * 定制 logback xml文件，从当前项目的\`classpath:configuration\`拷贝到指定的src/main/resources目录下 */ public class LogbackContributor extends SingleResourceProjectContributor { public LogbackContributor() { this(&#34;classpath:configuration/logback-spring.xml&#34;); } public LogbackContributor(String resourcePattern) { super(&#34;src/main/resources/logback-spring.xml&#34;, resourcePattern); } } 场景：按照统一规范生成目录结构。
/** * 按照规范生成默认的java目录结构 */ public class DefaultPackageContributor implements ProjectContributor { private final ProjectDescription description; public DefaultPackageContributor(ProjectDescription description) { this.description = description; } @Override public void contribute(Path projectRoot) throws IOException { Language language = description.getLanguage(); // &#34;src/main/java/com.test.demo&#34; Path packageRoot = projectRoot.resolve(&#34;src/main/&#34;) .resolve(language.id()) .resolve(description.getPackageName().replaceAll(&#34;\\\\.&#34;,&#34;/&#34;)); Files.createDirectories(packageRoot.resolve(&#34;config&#34;)); Files.createDirectories(packageRoot.resolve(&#34;dao&#34;)); Files.createDirectories(packageRoot.resolve(&#34;service&#34;)); Files.createDirectories(packageRoot.resolve(&#34;web&#34;)); } } 场景：在 xxx 条件下做 xxx。比如我们使用 spock 作为测试框架，spock 使用 groovy 语言。如果引入 spock 的时候，默认在 maven plugin 里增加 groovy 插件 gmavenplus-plugin。
class SpockMavenBuildCustomizer implements BuildCustomizer&lt;MavenBuild&gt; { @Override public void customize(MavenBuild build) { // add groovy plugin build.plugins() .add(&#34;org.codehaus.gmavenplus&#34;, &#34;gmavenplus-plugin&#34;); } } @ProjectGenerationConfiguration public class MyProjectGenerationConfiguration { @Bean @ConditionalOnRequestedDependency(&#34;spock&#34;) public SpockMavenBuildCustomizer spockMavenBuildCustomizer() { return new SpockMavenBuildCustomizer(); } } `}),e.add({id:6,href:"/bits-pieces/java/spring-boot/",title:"从Spring到Spring Boot",content:`从 Spring 到 Spring Boot，迁移升级使用过程，以及各种踩坑记录。
概述 从 Spring 到 Spring Boot，整体开发、运行方式主要变化。
- 当前模式 新模式（本地） 新模式（线上） 开发习惯 Spring + 外置 Tomcat Spring Boot（embed tomcat） Spring Boot War + 外置 Tomcat Java 版本 8、11、16、17 11、17(推荐) 11、17(推荐) Tomcat 版本 8.x、9.x 9.x 9.x 说明：
理论上支持 Java11，但是要求业务方尽量使用 Java17。 线上运行支持 Spring Boot jar 直接运行，但只开放给部分业务组，主要业务仍以 war + tomcat 为主。 快速开始 线下支撑系统导航，点击 脚手架 进入 spring start 页面，按自己需求选择模块，生成自己业务模式初始化代码。 写（Copy）业务代码到项目里，修改 pom.xml 根据需要添加新的依赖。 查看本文档中 遇见问题及解决方案 章节，注意如果是老项目迁移，这一步很重要。 本地开发工具启动 main 方法。 上线发布系统，选择 tomcat9:openjdk17 镜像，并勾选 镜像JDK版本编译代码。 以上生成的一个最简略的代码结构，更多复杂使用方式参考下方主要 starter 使用说明。
主要 starter 使用说明 文档会延后，代码不会骗人，更多说明参考各个项目源码的 README，README 会实时更新。
fxiaoke-spring-cloud-parent 目前有两个公司级父 pom：
新：com.fxiaoke.cloud.fxiaoke-spring-cloud-parent 用于 Spring Boot/Cloud 方式开发。 旧：com.fxiaoke.common.fxiaoke-parent-pom 用于原纯 Spring + Tomcat 方式开发。 注意：
这两个 pom 仍然都会更新，但不是实时同步，新 pom 更新一般比较晚。 旧 pom 区分线上和线下版本，新 pom 目前只有一份并不区分。 Maven 项目 parent 统一使用公司新 parent pom，这里定义了 Spring Boot、Spring Cloud 以及内部定制的各种 support 和 starter 版本号。
&lt;parent&gt; &lt;groupId&gt;com.fxiaoke.cloud&lt;/groupId&gt; &lt;artifactId&gt;fxiaoke-spring-cloud-parent&lt;/artifactId&gt; &lt;!-- 注意使用最新版本 --&gt; &lt;version&gt;1.1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; 主要升级项需关注：
Spock and Groovy：Spock 由原来的 1.x 升级到 2.x 版本，同时 Groovy 升级到 4.x 版本，Junit4 升级到 Junit5。 已知废弃依赖：
废弃项 替代项 说明 javax.annotation-api jakarta.annotation-api 随 spring boot 版本走，且两个包不能共存 spring-boot-starter-actuator 目前强制依赖 spring-boot-starter-actuator，容器镜像里使用它实现健康检查。 另外强制依赖 spring-boot-starter-web，因为有些基础组件依赖了 ServletContext。
注意： actuator 的引入会带来一些额外收益（或者叫坑），之前我们健康检测只检查服务端口活着，而 actuator 默认还额外检查各个中间件的状态，比如 ES 连接失败健康检查也会失败。如果业务方不希望检查，需要主动 exclude，具体方式和更多高级应用参考 spring-boot-starter-actuator 官方文档。
cms-spring-cloud-starter 配置中心 starter，类似 spring-cloud-consul/nacos/config，对接配置中心，实现配置文件动态加载、刷新，代替原 ReloadablePropertySourcesPlaceholderConfigurer。
使用步骤：
引入 starter。
&lt;dependency&gt; &lt;groupId&gt;com.fxiaoke.cloud&lt;/groupId&gt; &lt;artifactId&gt;cms-spring-cloud-starter&lt;/artifactId&gt; &lt;!-- 版本号建议不写，使用parent定义好的版本 --&gt; &lt;/dependency&gt; 增加 src/main/resources/application.properties 文件，内容如下。
# 当前模块名，必填，必须全局唯一，一般和maven子模块保持一致 spring.application.name=cms-starter-sample # 配置导入，这一行必须写。但是配置文件本身是否必须是通过optional控制的 spring.config.import=optional:cms:\${spring.application.name} 我们使用 spring.config.import 固定格式为 optional:cms:file-name。 optional 表示这个文件可选，配置中心不存在的时候也允许启动，cms 是固定字符代表对接 fs 配置中心。 同时支持多个，多个如果想写在一行，用分号分割。例如：
spring.config.import=optional:cms:\${spring.application.name};cms:dubbo-common 在 CMS 配置中心创建需要的配置文件，文件名为 spring-cloud-\${spring.application.name}，其中\${spring.application.name}替换成真正的文件名，注意当前版本自动追加了前缀spring-cloud-且不允许修改。
代码中使用几种方式参考 sample 代码，文档查看 spring 官方ConfigurationProperties和 @Value 说明。
配置变更后，如果想响应变更事件，实现自己逻辑，自定义类中implements ApplicationListener&lt;RefreshScopeRefreshedEvent&gt;
配置加解密，在配置中心中有个加密功能框（如果看不到可能是没有权限），先使用本 starter 的秘钥加密（注意：本 starter 使用了单独的秘钥），使用固定格式 ENC(加密后的内容)配置到文件里，在 java 里 get value 就是已经解密后的了。例如：
sample.sensitive=ENC(30E239E0958AF3179C7E8EBA3DF618FD) 响应配置更新：
对于使用使用 ConfigurationProperties 映射的对象类，从对象中每次 get 的值都是刷新后的。推荐这种方式。
@Data @Configuration @ConfigurationProperties(prefix = &#34;sample&#34;) public class SampleProperties { private String name; } @RefreshScope + @Value 获取 Value 注解的新值。
@Service @RefreshScope public class ValueService { @Value(&#34;\${sample.over.value}&#34;) @Getter private String watchValue; } 监听 RefreshScopeRefreshedEvent 事件。
@EventListener(RefreshScopeRefreshedEvent.class) public void handlerPropertiesChangeEvent(RefreshScopeRefreshedEvent event) { //此时配置Bean已刷新完成，处理自己的业务逻辑 } 老项目迁移升级 POM 迁移，依赖项可能被开源软件主动提升版本，要注意版本变化。已知的组件会通过 fxiaoke parent 控制。 原有的 xml 配置，可以改为注解形式，也可以不改直接 @ImportResource 使用。 注意配置扫描范围，原来 xml 中可能是配置是某几个包，Spring Boot 默认扫描 Application.java 所在包，范围可能扩大。 原来 tomcat web.xml 相关配置，尤其是各种 filter、servlet，需要迁移。包括我们自定义的一些工具。 Unit Test 更换注解，目前默认 junit 版本是 junit5，原 junit4 注解位置变更。 迁移辅助 辅助工具： 使用 EMT4J 提前扫描，通过静态检测指导从 Java 8 升级到 Java 17 需要注意的变更项。
War 配置转移 If you try to migrate a Java legacy application to Spring Boot you will find out that Spring Boot ignores the web.xml file when it is run as embedded container.
webapp web.xml 配置如何转移到 spring boot war 形式。 参考：https://www.baeldung.com/spring-boot-dispatcherservlet-web-xml
已知限制 目前发现几个体验不太好的地方，正在想办法优化。
引入我们的 support，常常触发 Spring Auto Config（尤其是 ConditionOnClass 类型的），而我们的 support 有些未适配成 starter，需要开发人员主动排除默认的实现。 遇见问题及解决方案 PostConstruct 和 PreDestroy 注解不生效 原因：PostConstruct、PreDestroy 等注解可能存在多个实现或者过个版本，比如以下 jar 包都可能包含：
javax.annotation-api-1.3.2.jar jakarta.annotation-api-1.3.5.jar jboss-annotations-api_1.3_spec-2.0.1.Final.jar 解决方法：排除依赖，只保留 jakarta.annotation-api 一种，且只能有一个版本。
kafka 使用报错，日志类似如下： ERROR c.f.s.SenderManager cannot send, org.apache.kafka.common.KafkaException: org.apache.kafka.clients.producer.internals.DefaultPartitioner is not an instance of org.apache.kafka.clients.producer.Partitioner 原因：因为 classpath 下包含多个不同版本的 kafka-client.jar，检查依赖项，确保只引用一个版本。
告警：SLF4J: Class path contains multiple SLF4J bindings. 多个 jar 包含 SLF4J 实现，或引入了多个 logback 版本，请根据提示排除不需要的 jar 包。
XML 中使用 AOP 注解，运行期报错如下（建议用到 AOP 的提前检查，因为运行期才会报错）：JoinPointMatch ClassNotFoundException Caused by: java.lang.ClassNotFoundException: org.aspectj.weaver.tools.JoinPointMatch at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1412) at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1220) ... 58 more 依赖 spring aop，请确认是否引入 spring-boot-starter-aop。
本地使用 Java 17 启动，类似如下报错。 ERROR o.s.b.SpringApplication Application run failed java.lang.reflect.InaccessibleObjectException: Unable to make protected final java.lang.Class java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain) throws java.lang.ClassFormatError accessible: module java.base does not &#34;opens java.lang&#34; to unnamed module @443118b0 at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354) at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297) at java.base/java.lang.reflect.Method.checkCanSetAccessible(Method.java:199) at java.base/java.lang.reflect.Method.setAccessible(Method.java:193) at com.alibaba.dubbo.common.compiler.support.JavassistCompiler.doCompile(JavassistCompiler.java:123) [6 skipped] at com.alibaba.dubbo.common.compiler.support.AbstractCompiler.compile(AbstractCompiler.java:59) at com.alibaba.dubbo.common.compiler.support.AdaptiveCompiler.compile(AdaptiveCompiler.java:46) 本地命令行中启动参数里主动追加以下参数（这些参数在发布系统的镜像里默认已经加了），IDEA 启动是设置到VM options里：
--add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.rmi/sun.rmi.transport=ALL-UNNAMED Bean 重复定义错误，报错信息类似如下。 The bean &#39;eieaConverterImpl&#39;, defined in class path resource [spring/ei-ea-converter.xml], could not be registered. A bean with that name has already been defined in class path resource [spring/ei-ea-converter.xml] and overriding is disabled. Action: Consider renaming one of the beans or enabling overriding by setting spring.main.allow-bean-definition-overriding=true 可能因为注解扫描范围增广或者有同样包多版本引入，导致扫描到多个。确认多处定义是否一致，如果不一致查看原项目哪个生效，以生效为准。如果一致，找到定义的地方查看是否能整个文件排除掉，实在不能再设置 spring.main.allow-bean-definition-overriding=true。
如下报错 class xxx is not visible from class loader，常见于 dubbo 服务。 解决办法：不要用 spring-boot-devtools。 参考链接：https://blog.csdn.net/zhailuxu/article/details/79305661 dubbo 服务 java.io.IOException: invalid constant type: 18，日志类似如下： Wrapped by: java.lang.IllegalStateException: Can not create adaptive extenstion interface com.alibaba.dubbo.rpc.Protocol, cause: java.io.IOExc eption: invalid constant type: 18 at com.alibaba.dubbo.common.extension.ExtensionLoader.createAdaptiveExtension(ExtensionLoader.java:723) at com.alibaba.dubbo.common.extension.ExtensionLoader.getAdaptiveExtension(ExtensionLoader.java:455) ... 29 common frames omitted Wrapped by: java.lang.IllegalStateException: fail to create adaptive instance: java.lang.IllegalStateException: Can not create adaptive extens tion interface com.alibaba.dubbo.rpc.Protocol, cause: java.io.IOException: invalid constant type: 18 at com.alibaba.dubbo.common.extension.ExtensionLoader.getAdaptiveExtension(ExtensionLoader.java:459) at com.alibaba.dubbo.config.ServiceConfig.&lt;clinit&gt;(ServiceConfig.java:51) ... 28 common frames omitted 原因：缺少 javassist 或 javassist 版本太低。目前可用的版本是 javassist:javassist:3.27.0-GA。
Spring Auto Configuration 常见排除： @SpringBootApplication(exclude = {DataSourceAutoConfiguration.class, MongoDataAutoConfiguration.class}) 参考资料 我服了！SpringBoot 升级后这服务我一个星期都没跑起来： https://www.toutiao.com/article/7163602391366074916/?app=news_article&amp;timestamp=1667992250&amp;use_new_style=1&amp;req_id=20221109191050010158031044021CE00D&amp;group_id=7163602391366074916&amp;share_token=A8B008C4-29B7-4ADD-8636-3A17BA91A3BA&amp;tt_from=weixin&amp;utm_source=weixin&amp;utm_medium=toutiao_ios&amp;utm_campaign=client_share&amp;wxshare_count=1&amp;source=m_redirect&amp;wid=1668061929517 `}),e.add({id:7,href:"/bits-pieces/devops/cdr/",title:"使用Visual Studio Code搭建多用户远程IDE",content:`Securing Visual Studio code-server, support multi-user.
为 code-server（VS Code Web 版） 增加外部认证，并支持多用户，不同用户的 code-server 实例完全隔离。
主要为了解决问题：
code-server 本身支持配置文件形式的用户名密码认证（截止目前，以后也许会改进）。所以引入了外部认证系统，Google、GitHub、 okta、CAS、Keycloak 等理论上都是支持的。
code-server 默认没有数据隔离，所以又加了一层 proxy，为每个用户创建一个（或多个）code-server 实例，以实现用户间的数据隔离。
使用开源 Auth Proxy，自己不需要实现复杂的登录流程了，比如 code flow with pkce 对大部分人来说读懂这个协议都很困难。
使用组件 keycloak
Redhat 开源 IAM 系统，提供用户、组织服务，提供标准 OIDC。
oauth2-proxy
认证代理，配合 keycloak 提供完整 OAuth2 Code Flow 认证流程。也可以试试 pomerium，看样子也不错。
架构图如下。
核心逻辑 架构图简单解读，所有过程官方文档都有详细说明，都是配置，以官方配置为准。
keycloak 创建 client，使用 OIDC 协议，作为 oauth2-proxy 的 provider。
ingress(nginx) 使用 auth_request 指令拦截所有请求，从 oauth2-proxy 进行代理认证，配置可参考 oauth2-proxy auth_request 指导。
nginx.ingress.kubernetes.io/auth-signin: https://$host/oauth2/start?rd=$escaped_request_uri nginx.ingress.kubernetes.io/auth-url: https://$host/oauth2/auth 认证通过后，将用户名/ID 作为标识，通过 Http Header (举例如 X-Forwarded-Preferred-Username) 传入 upstream。
gateway(nginx) 从 Header 中获取用户标识，代理到此用户对应的 code-server 实例。
location / { …… proxy_pass http://code-server-$http_x_forwarded_for_preferred_username; } code-server 各个实例部署时，以免认证方式部署。
每个 code-server 实例挂载不同的存储，实现完全隔离。
`}),e.add({id:8,href:"/bits-pieces/devops/mysql5.7to8.0/",title:"MySQL5.7升级至8.0",content:`MySQL 5.7 升级至 8.0，程序适配以及踩坑记录。
代码适配方案 mysql-connector-java.jar 升级到 8.0.21 版本。 com.mysql.jdbc.Driver 更换为 com.mysql.cj.jdbc.Driver。 链接 url 里指定 useSSL=false。 链接 url 中显式指定时区，增加 serverTimezone=Asia/Shanghai。 兼容性问题 com.mysql.jdbc.exceptions.jdbc4 在 MySQL Connector 8 中不存在。
将 mysql-connector-java 版本，升级到 8.0 后，如果项目中有使用 mysql 的 Exception 类，编译时会收到以下错误
error: package com.mysql.jdbc.exceptions.jdbc4 does not exist [ERROR] import com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException; [ERROR] import com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException; MySQL 在 8.0 版本重用了现有的 java.sql 异常类，取消了 exceptions.jdbc4 的异常类，整改的异常映射关系如下。
5.7 版本异常类 8.0 版本异常类 com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException java.sql.SQLSyntaxErrorException com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException java.sql.SQLIntegrityConstraintViolationException com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException java.sql.SQLTransactionRollbackException 数据库关键字扩充问题。
在适配 MySQL 8.0 的时候遇到如下报错。
Caused by: java.sql.SQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;, source, i18n_lang&#39; at line 5 问题的原因是：MySQL 新增了一批关键字，在使用过程中，如果字段名称和关键字重复，则需要在字段名称上增加单引号方可使用。RANK 为新增关键字。如下所示：
&lt;result column=&#34;rank&#34; jdbcType=&#34;INTEGER&#34; property=&#34;rank&#34;/&gt; 新增关键字列表如下。
ACTIVE , ADMIN , ARRAY , ATTRIBUTE , BUCKETS , CLONE , COMPONENT , CUME_DIST (R) , DEFINITION , DENSE_RANK (R) , DESCRIPTION , EMPTY (R) , ENFORCED , ENGINE_ATTRIBUTE , EXCEPT (R) , EXCLUDE , FAILED_LOGIN_ATTEMPTS , FIRST_VALUE (R) , FOLLOWING , GEOMCOLLECTION , GET_MASTER_PUBLIC_KEY , GROUPING (R) , GROUPS (R) , HISTOGRAM , HISTORY , INACTIVE , INVISIBLE , JSON_TABLE (R) , JSON_VALUE , LAG (R) , LAST_VALUE (R) , LATERAL (R) , LEAD (R) , LOCKED , MANAGED , MASTER_COMPRESSION_ALGORITH , MSMASTER_PUBLIC_KEY_PATH , MASTER_TLS_CIPHERSUITES , MASTER_ZSTD_COMPRESSION_LEVEL , MEMBER , NESTED , NETWORK_NAMESPACE , NOWAIT , NTH_VALUE (R) , NTILE (R) , NULLS , OF (R) , OFF , OJ , OLD , OPTIONAL , ORDINALITY , ORGANIZATION , OTHERS , OVER (R) , PASSWORD_LOCK_TIME , PATH , PERCENT_RANK (R) , PERSIST , PERSIST_ONLY , PRECEDING , PRIVILEGE_CHECKS_USER , PROCESS , RANDOM , RANK (R) , RECURSIVE (R) , REFERENCE , REQUIRE_ROW_FORMAT , RESOURCE , RESPECT , RESTART , RETAIN , RETURNING , REUSE , ROLE , ROW_NUMBER (R) , SECONDARY , SECONDARY_ENGINE , SECONDARY_ENGINE_ATTRIBUTE , SECONDARY_LOAD , SECONDARY_UNLOAD , SKIP , SRID , STREAM , SYSTEM (R) , THREAD_PRIORITY , TIES , TLS , UNBOUNDED , VCPU , VISIBLE , WINDOW (R) `}),e.add({id:9,href:"/bits-pieces/devops/mysql-large-import/",title:"MySQL大文件导入优化",content:`项目中需要根据SQL文件导入数据，文件大约20G，正常导入约需要2小时，如何加快导入速度。
如果一个SQL文件只有一个表的数据，可以直接使用mysql load data infile 语法，速度比较快。
我们是一个SQL文件包含了很多表，导入过程经过如下设置，20G大约需要40分钟。
# 进入mysql mysql -u root -p # 创建数据库（如果已经有数据库忽略此步骤） CREATE DATABASE 数据库名; # 设置参数 set sql_log_bin=OFF;//关闭日志 set autocommit=0;//关闭autocommit自动提交模式 0是关闭 1 是开启（默认） set global max_allowed_packet = 20 *1024* 1024 * 1024; # 使用数据库 use 数据库名; # 开启事务 START TRANSACTION; # 导入SQL文件并COMMIT（因为导入比较耗时，导入和COMMIT一行命令） source 文件的路径; COMMIT; `}),e.add({id:10,href:"/bits-pieces/knives/",title:"瑞士军刀",content:`程序员常用优秀工具、软件、类库，上榜都是有理由的。
Rust 命令行工具 procs 比 ps 好用的工具，查看路径和端口一步到位，支持过滤。
ripgrep ripgrep 简称 rg，是一个面向行的搜索工具，Rust 编写，全平台支持，也是 VS Code 的默认搜索工具。它的搜索性能极高，在大项目中也有着出色的表现，并且默认可以忽略 .gitignore 文件中的内容，非常实用。
除了作为一个高效的命令行工具使用外，整个项目的设计也不错，另外还是一个学习 Rust 的好项目。
rg -h 开启探索之旅吧。
TL;DR Too Long; Didn’t Read.
tldr 根据二八原则，简化了烦琐的 man 指令帮助文档，仅列出常用的该指令的使用方法，让人一看就懂，大多数情况下，给出几个指令的使用 demo 可能正是我们想要的。
举个例子看下实际运行效果，如下。
➜ ~ tldr docker Manage Docker containers and images. Some subcommands such as \`docker run\` have their own usage documentation. More information: &lt;https://docs.docker.com/engine/reference/commandline/cli/&gt;. List currently running docker containers: docker ps List all docker containers (running and stopped): docker ps -a Start a container from an image, with a custom name: docker run --name container_name image Start or stop an existing container: docker start|stop container_name Pull an image from a docker registry: docker pull image Open a shell inside a running container: docker exec -it container_name sh Remove a stopped container: docker rm container_name Fetch and follow the logs of a container: docker logs -f container_name tldr 命令行有多种实现，比如官方推荐的有 npm 和 python。
npm install -g tldr pip3 install tldr 个人更喜欢 Rust 版本的实现 tealdeer，支持各系统包管理器和二进制安装，比如 homebrew。
brew install tealdeer fd fd，find 的替代品。
`}),e.add({id:11,href:"/bits-pieces/windows/",title:"Windows",content:`Windows 下工作常用命令、工具、软件总结。
`}),e.add({id:12,href:"/bits-pieces/windows/takeown/",title:"Windows提权 + 设置环境变量",content:`背景：公司 Windows 办公机受域控安全策略限制，部分文件无权修改，另外开发常用的设置系统环境变量也变灰无法设置。此问题解决方式如下。
提升文件权限 点击 Windows + X 快捷键 – 选择「命令提示符（管理员）。
在 CDM 窗口中执行如下命令。
takeown /f C:\\要修复的文件路径 在拿到文件所有权后，还需要使用如下命令获取文件的完全控制权限。
icacls C:\\要修复的文件路径 /Grant Administrators:F 命令行设置环境变量 Windows 下命令行设置环境变量，方式为 setx 变量名 变量值，变量值带空格等特殊符号的，用引号引起来。
# 通过命令行设置 Java Home setx JAVA_HOME &#34;C:\\Program Files\\Java\\jdk-11.0.2&#34; # 设置 GO Path setx GOPATH &#34;D:\\workspace\\go&#34; `}),e.add({id:13,href:"/bits-pieces/kubernetes/cka/",title:"备考 CKA 过程，CKA 真题",content:`备考 CKA （Certified Kubernetes Administrator）过程，心得，遇见问题，CKA 真题。
备考环境 备考使用的系统和软件版本如下。
Ubuntu：20.04 Focal Fossa Kubernetes：1.20.7 kubeadm：1.20.7 安装和使用问题记录 kubeadm 安装问题 安装 kubeadm，国内安装使用阿里镜像源。
$ cat /etc/apt/sources.list.d/kubernetes.list deb https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main 踩坑：因为使用的是 ubuntu 20.04，代号 focal，专门去各个代理镜像源找kubernetes-focal都没有找到，后来发现 google 官方根本没发布对应的版本，只有kubernetes-xenial， k8s 官方文档里 ubuntu 也是用的这一个版本。可以用，就用他吧。
kubeadm init 时指定使用阿里镜像源（解决国内连不上 k8s.gcr.io 的问题）、指定版本号(安装考试对应的版本，不一定是最新版本)。
通过指定--image-repository，不需要手动下载镜像重新打 tag，kubeadm 自动使用指定的 repository。
kubeadm init --image-repository=registry.aliyuncs.com/google_containers \\ --pod-network-cidr=10.244.0.0/16 \\ --kubernetes-version=v1.20.7 解决 scheduler Unhealthy，controller-manager Unhealthy 第一次安装完成后通过 kubectl get cs命令，发现 scheduler Unhealthy，controller-manager Unhealthy。
$ kubectl get cs NAME STATUS MESSAGE scheduler Unhealthy Get &#34;http://127.0.0.1:10251/healthz&#34;: dial tcp 127.0.0.1:10 controller-manager Unhealthy Get &#34;http://127.0.0.1:10252/healthz&#34;: dial tcp 127.0.0.1:10 查看本机端口，10251 和 10252 都没有启动。
确认 schedule 和 controller-manager 组件配置是否禁用了非安全端口。
查看配置文件，路径分别为：/etc/kubernetes/manifests/kube-scheduler.yaml 和 /etc/kubernetes/manifests/kube-controller-manager.yaml 将两个配置文件中 --port=0 注释掉（注释掉是否合适待商量）。
spec: containers: - command: - kube-scheduler - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf - --bind-address=127.0.0.1 # 注释掉port，其他行原样不要动 - --port=0 解决 master 无法调度 我的环境是单节点，既当 master 又当 worker，kubeadm 安装完成后默认 master 节点是不参与调度的，pod 会一直 pending。
kubectl describe node 发现 node 的 Taints 里有 node-role.kubernetes.io/master:NoSchedule。
设置 k8s master 节点参与 POD 调度。
kubectl taint nodes your-node-name node-role.kubernetes.io/master- 考试心得 刷新浏览器会导致考试被终止。
提前演练敲一遍，时间其实挺紧张。
官方kubectl Cheat Sheet章节非常有用，必考。
命令自动补全 source &lt;(kubectl completion bash)。
尽量使用命令创建 Pod、deployment、service。
kubectl run podname --image=imagename --restart=Never -n namespace kubectl run &lt;deploymentname&gt; --image=&lt;imagename&gt; -n &lt;namespace&gt; kubectl expose &lt;deploymentname&gt; --port=&lt;portNo.&gt; --name=&lt;svcname&gt; 使用 dry-run。
kubectl run &lt;podname&gt; --image=&lt;imagename&gt; --restart=Never --dry-run -o yaml &gt; title.yaml 使用 kubectl -h 查看各个命令的帮助，很多都在 Examples 里。比如 kubectl expose -h。
CKA 真题练习 真题会过时，别指望着刷刷题就通过考试，老老实实学一遍。
将所有 pv 按照 name/capacity 排序。
# sort by name kubectl get pv --sort-by=.metadata.name # sort by capacity kubectl get pv --sort-by=.spec.capacity.storage deployment 扩容。
kubectl scale deployment test --replicas=3 Set the node named ek8s-node-1 as unavaliable and reschedule all the pods running on it.
kubectl cordon ek8s-node-1 # drain node的时候可能出错，根据错误提示加参数 kubectl drain ek8s-node-1 --delete-local-data --ignore-daemonsets --force Form the pod label name-cpu-loader,find pods running high CPU workloads and write the name of the pod consuming most CPU to the file /opt/KUTR00401/KURT00401.txt(which alredy exists).
# 注意题目中并没有提namespace，可以先看下这个label的pod在哪个namespace，确定命令中要不要加namespace kubectl top pods -l name=name-cpu-loader --sort-by=cpu echo &#39;排名第一的pod名称&#39; &gt;&gt;/opt/KUTR00401/KUTR00401.txt `}),e.add({id:14,href:"/bits-pieces/",title:"bits and pieces",content:` I always have a lot of bits and pieces in my coat pocket.
只是些日常琐碎笔记，目前看并没什么大用，翻翻看总还是有惊喜。
License Licensed under CC BY-NC 4.0. 2020-2022 nxest.com.
`}),e.add({id:15,href:"/bits-pieces/devops/",title:"DevOps",content:`DevOps 相关的技术选型、算法研究、实战经验教训。
`}),e.add({id:16,href:"/bits-pieces/devops/nexus/",title:"Nexus3 批量导入",content:`应用场景：
从一个可联网镜像仓库迁移到另一个无法联网的镜像仓库，涉及 Java 和 JavaScript 依赖包。 源镜像仓库比较大（10T），新镜像仓库只需要部分依赖，不需要全量导入。 Nexus 配置 Repository 在 nexus 上创建 Java 和 NPM Repository。
注意：
创建时类型选择 hosted。 对于 Java Repository 可根据实际情况将 Version Policy 选择 mixed。 Deployment Policy 选择 Allow redeploy，便于后续重复导入。 导入 Java 依赖包 准备 Java 依赖包：将本地 maven 或 gradle 的存储目录(默认$USER/.m2/repository)清空，重新执行命令，获取干净的 repository。
从 nexus-repository-import-scripts 获取 mavenimport.sh 文件。
将 mavenimport.sh copy 到 repository 文件夹内
执行以下命令开始导入，注意换成自己的 admin 密码，修改端口和 Repository。
cd repository &amp;&amp; chmod +x mavenimport.sh ./mavenimport.sh -u admin -p admin123 -r http://127.0.0.1:8081/repository/your-repo-name/ 以上命令开始导入，可能时间较长，可以去界面上刷新下 jdf 的 repository 看看有没有导进去。
导入 NPM 依赖包 导入前端 npm 包就是先下载好各个包的 tgz 文件，然后根据 tgz 文件执行 npm publish。
准备前端依赖包：使用这个工具 node-tgz-downloader，根据他的说明，先下载好各个 js 的 .tgz文件，默认下载到一个叫 tarballs 的文件夹内，下载成功后大致结果如下，如果 nodejs 版本比较低可能下载失败，可以尝试使用低版本的 node-tgz-downloader。
tarballs ├── @babel │ ├── code-frame │ │ ├── code-frame-7.12.11.tgz │ │ └── code-frame-7.16.0.tgz │ ├── compat-data │ │ └── compat-data-7.16.4.tgz │ ├── core │ │ └── core-7.16.0.tgz │ ├── generator │ │ └── generator-7.16.0.tgz │ ├── helper-annotate-as-pure │ │ └── helper-annotate-as-pure-7.16.0.tgz 从 nexus-repository-import-scripts 获取 npmimport.sh 文件。
将 npmimport.sh copy 到 tarballs 文件夹内。
登录 npm 账户，开始执行导入。
npm config set registry=http://127.0.0.1:8081/repository/your-npm-repo/ npm adduser --registry=http://127.0.0.1:8081/repository/your-npm-repo/ cd tarballs &amp;&amp; chmod +x npmimport.sh ./npmimport.sh -r http://127.0.0.1:8081/repository/your-npm-repo/ 以上命令开始导入，可能时间较长，可以去界面上刷新下 npm 的 repository 看看有没有导进去。
客户端使用 Maven 修改 setting.xml，使用私有仓库。
另外因为部分包不受自己控制，可能缺少 metadata，执行 mvn package 等命令时，注意增加 -c 参数忽略 checksum。
如：mvn -c clean package -Dmaven.test.skip=true
`}),e.add({id:17,href:"/bits-pieces/devops/superset/",title:"Superset 对接 ClickHouse",content:`Apache Superset，开源数据分析与可视化平台。
常用功能：
SQL 查询，作为一个 Web 版本的 ClickHouse、MySQL 等等多种数据源的客户端。 支持对查询结果再进行过滤，直接 copy 或下载查询结果，保存查询条件，分享查询条件等。 丰富的图表设计、分析。内置各种 Charts 图表，支持自定义 Charts 和 Dashboard，需要自己根据业务动手制作，这才是他的主业。 支持用户管理，基于 RBAC 模型的控制权限。（理论上可以对接 keycloak，看 issue 还不完善可能需要改 python 代码）。 配置文件 全部默认配置文件参考superset/config.py。
如果想自定义，创建一个 superset_config.py 文件放到 python path。
中文支持 多语言默认是不打开的（因为维护的不好，英文属于正常维护，其他语言属于有空就维护），需要在 superset_config.py 中增加环境变量，支持中文。
# 默认中文 BABEL_DEFAULT_LOCALE=&#39;zh&#39; # 支持很多其他语言，裁掉一部分，只留了这两个 LANGUAGES = { &#34;en&#34;: {&#34;flag&#34;: &#34;us&#34;, &#34;name&#34;: &#34;English&#34;}, &#34;zh&#34;: {&#34;flag&#34;: &#34;cn&#34;, &#34;name&#34;: &#34;中文&#34;}, } `}),e.add({id:18,href:"/bits-pieces/linux/history/",title:"History入门",content:`Linux 下 history 命令，用好历史命令提高工作效率。
搜索历史命令 快捷键 Ctrl + r
非常建议你使用这个命令, 因为当你曾经输过一个很长的命令之后, 当你再次想输入这个命令的时候, 你就可以按下这个快捷键, 然后键入那条长命令的关键词, 然后就会显示出含有那个关键词的命令, 每次按下这个键都会再往上搜一个。可以找个机器实际体会下，确实很常用。
重复上一次的命令 向上的方向键。上下键翻看历史命令，翻到想执行的命令回车。
两个叹号: ！！
还有这个：！-1
快捷键：Ctrl+p 或 Ctrl+n，向上和向下翻看历史命令，和上下键效果一样。
从历史记录中执行某个命令 还是沿袭上一个中的 !-n 模式, 其中 n 是一个编号。如下示例，执行了编号为 4 的命令。
1 service network restart 2 exit 3 id 4 cat /etc/redhat-release # !4 cat /etc/redhat-release 执行曾经的命令中特定开头的 假设你的部分历史命令如下:
1721 find . -type f 那么, 怎样重复执行 1721 条呢? 除了利用 !-1721 这么麻烦的方法，我们还可以用 !f 这样的姿势。因为开头的 f 是离着最后一条命令最近的, 所以 !f 就执行了它。
清空历史记录 history -c 在历史记录中显示时间 我们可以用 HISTTIMEFORMAT 这个变量来定义显示历史记录时的时间参数:
# export HISTTIMEFORMAT=&#39;%F %T &#39; # history 也可以用下面的别名来定义显示历史命令的数量:
alias h1=&#39;history 10&#39; 用 HISTCONTROL 来删除重复的历史记录 下面的例子中, 有三个 pwd 命令, 那么在 history 中就会显示三次 pwd , 有点不那么人性化。
# pwd # pwd # pwd # history | tail -4 44 pwd 45 pwd 46 pwd 47 history | tail -4 所以我们可以这样修改:
export HISTCONTROL=ignoredups 然后就不会出现相邻的重复记录了。
History 扩展和总结 用这个功能可以选择特定的历史记录, 不论是修改还是立即执行, 都可以完成。
!! 重复上一条命令。
!10 重复历史记录中第 10 条命令。
!-2 重复历史记录中倒数第二条命令。
!string 重复历史记录中最后一条以 string 开头的命令。
!?string 重复历史记录中最后一条包含 string 的命令。
`}),e.add({id:19,href:"/bits-pieces/java/",title:"Java",content:`Oh，Java。
`}),e.add({id:20,href:"/bits-pieces/kubernetes/",title:"Kubernetes",content:""}),e.add({id:21,href:"/bits-pieces/linux/",title:"Linux",content:`Linux 下工作常用命令、工具、软件总结。
Ubuntu Ubuntu 查询指定软件有多少可用版本:
apt-cache madison &lt;&lt;package name&gt;&gt; 安装软件时指定版本号：
$ apt-get install &lt;&lt;package name&gt;&gt;=&lt;&lt;version&gt;&gt; # apt-get install kubeadm=1.20.7-00 查看 Ubuntu 版本代号：
$ sb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.2 LTS Release: 20.04 Codename: focal `}),e.add({id:22,href:"/bits-pieces/linux/shell-coding/",title:"Shell 编程实用句式",content:"选婿。\n#!/usr/bin/env bash #!/usr/bin/bash 检查是否以 root 用户执行。\n# check if run as root user if [[ `id -u` -ne 0 ]]; then echo &#34;You need root privileges to run this script.&#34; fi 获取正在执行脚本的绝对路径，注意直接用 $0 或 pwd 获取的可能都不要你想要的。\ncurrent_dir=$(cd `dirname $0`;pwd) 为当前目录包含子目录下所有 .sh 文件增加可执行权限。\nchmod +x `find . -name &#39;*.sh&#39;` 将提示信息显示到终端（控制台），同时也写入到文件里。\nlog_file=/var/log/test.log echo &#34;This line will echo to console and also write to log file.&#34; | tee -a ${log_file} 类似于 Java properties 中 key=value 形式的字符串，取 key 和 value 的值。\nusername_line=&#34;username=test&#34; #key is username key=${username_line%=*} #val is test val=${username_line#*=} 实现 trim 效果。\n#trim string by echo val_trim=$(echo -n ${val}) 字体输出颜色及终端格式控制\n#字体色范围：30-37 echo -e &#34;\\033[30m 黑色字 \\033[0m&#34; echo -e &#34;\\033[31m 红色字 \\033[0m&#34; echo -e &#34;\\033[32m 绿色字 \\033[0m&#34; echo -e &#34;\\033[33m 黄色字 \\033[0m&#34; echo -e &#34;\\033[34m 蓝色字 \\033[0m&#34; echo -e &#34;\\033[35m 紫色字 \\033[0m&#34; echo -e &#34;\\033[36m 天蓝字 \\033[0m&#34; echo -e &#34;\\033[37m 白色字 \\033[0m&#34; #字背景颜色范围：40-47 echo -e &#34;\\033[40;37m 黑底白字 \\033[0m&#34; echo -e &#34;\\033[41;30m 红底黑字 \\033[0m&#34; echo -e &#34;\\033[42;34m 绿底蓝字 \\033[0m&#34; echo -e &#34;\\033[43;34m 黄底蓝字 \\033[0m&#34; echo -e &#34;\\033[44;30m 蓝底黑字 \\033[0m&#34; echo -e &#34;\\033[45;30m 紫底黑字 \\033[0m&#34; echo -e &#34;\\033[46;30m 天蓝底黑字 \\033[0m&#34; echo -e &#34;\\033[47;34m 白底蓝字 \\033[0m&#34; "}),e.add({id:23,href:"/bits-pieces/linux/tcpdump/",title:"tcpdump",content:`tcpdump 捕捉网卡eth0流量，并存入到out.pcap文件中。
sudo tcpdump -vv -s0 -i eth0 -w out.pcap `}),e.add({id:24,href:"/bits-pieces/kubernetes/tldr/",title:"TL;DR",content:`复制&ndash;粘贴，这就是生活。
复制 secret 到另一个 namespace。
kubectl get secret mys --namespace=na -oyaml | grep -v &#39;^\\s*namespace:\\s&#39; | kubectl apply --namespace=nb -f - 批量删除 pod。
kubectl get pods --all-namespaces | grep Evicted | awk &#39;{print $2 &#34; --namespace=&#34; $1}&#39; | xargs kubectl delete pod # Delete by label kubectl delete pod -n idaas-book -l app.kubernetes.io/name=idaas-book 密钥解密。
kubectl get secret my-creds -n mysql -o jsonpath=&#34;{.data.ADMIN_PASSWORD}&#34; | base64 --decode Docker 保存和导入镜像。
# save image(s) docker save image:tag image2:tag | gzip &gt;xxx.tar.gz # load images docker load -i xxx.tar.gz 合并多个 kube config。
export KUBECONFIG=~/.kube/config:~/.kube/anotherconfig kubectl config view --flatten &gt; ~/.kube/config-all cp ~/.kube/config-all ~/.kube/config # 顺手把权限改了，避免helm或kubectl客户端warning chmod 600 ~/.kube/config `}),e.add({id:25,href:"/bits-pieces/linux/tar.gz/",title:"文件压缩解压",content:`常用文件格式 .tar：tar 其实打包（或翻译为归档）文件，本身并没有压缩。在 Linux 里 man tar 可以看到它的描述也是“manipulate tape archives”（tar 最初被用来在磁带上创建档案，现在，用户可以在任何设备上创建档案，只是它的描述还没有改）。
.gz：gzip 是 GNU 组织开发的一个压缩程序，.gz 结尾的文件就是 gzip 压缩的结果。
.bz2：bzip2 是一个压缩能力更强的压缩程序，.bz2 结尾的文件就是 bzip2 压缩的结果。
.Z：compress 也是一个压缩程序。.Z 结尾的文件就是 compress 压缩的结果。
.zip：使用 zip 软件压缩的文件。
.tar.gz、.tar.bz2、.tar.xz 等可以理解为打包+压缩的效果，用软件解压可以发现比.gz 多了一层包。gzip 和 bzip2，不能同时压缩多个文件，tar 相当于开个挂加上同时压缩的特效，tar 先归档为一个大文件，而归档为大文件的速度是很快的，测试了一下几乎可以忽略不计。
除了这些格式外，常见的 deb、exe、msi、rpm、dmg、iso 等安装软件，其实都是经过压缩的，一般情况下没有必要再压缩。而 rar 基本认为是 Windows 平台专属的压缩算法了，各个 Linux 发行版都不自带 rar 压缩解压缩软件，所以可以看到很多软件发行的格式都是 .tar.gz 或 .zip。
解压缩 根据文件名后缀自行选择解压缩命令。
tar -xf test.tar gzip -d test.gz gunzip test.gz # -C 直接解压到指定目录 tar -xzf test.tar.gz -C /home bzip2 -d test.bz2 bunzip2 test.bz2 tar -xjf test.tar.bz2 tar -xvJf test.tar.xz 压缩 请根据需要选择压缩算法。
# 将当前目录下所有jpg格式的文件打包为pictures.tar tar -cf pictures.tar *.jpg # 将Picture目录下所有文件打包并用gzip压缩为pictures.tar.gz tar -czf pictures.tar.gz Picture/ # 将Picture目录下所有文件打包并用bzip2压缩为pictures.tar.bz2 tar -cjf pictures.tar.bz2 Picture/ `}),e.add({id:26,href:"/bits-pieces/linux/pngquant/",title:"PNG图片批量压缩",content:"使用 pngquant 命令行批量压缩 PNG 图片。\npngquant 压缩当前目录下全部 PNG 文件，并且默认全覆盖已有。\nfor file in $(ls *.png) do pngquant $file --force --output $file done "}),e.add({id:27,href:"/bits-pieces/linux/transaction/",title:"数据库事务控制",content:`数据库事务总结，主要包括数据库事务 ACID 属性介绍、数据库并发问题总结、事务传播行为和隔离级别。
概念 事务（Transaction）是并发控制的基本单位。它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。标准定义：指作为单个逻辑工作单元执行的一系列操作，而这些逻辑工作单元需要具有原子性， 一致性，隔离性和持久性四个属性，统称为 ACID 特性。
Atomic（原子性） 事务中包含的操作被看做一个不可分割的逻辑单元，这个逻辑单元中的操作要么全部成功，要么全部失败。
Consistency（一致性） 事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。只有合法的数据可以被写入数据库，否则事务应该将其回滚到最初状态。关于数据库一致性，更专业的解释请参考专业的书籍。
Isolation（隔离性） 事务允许多个用户对同一个数据进行并发访问，而不破坏数据的正确性和完整性。同时，并行事务的修改必须与其他并行事务的修改相互独立。
Durability（持久性） 事务提交后，对系统的影响是永久的。简单理解就是写进去了，不会因为时间、系统环境，关机重启等变化而变化。
数据库并发问题 数据库是共享资源，通常有许多个事务同时在运行。当多个事务并发地存取数据库时就会产生同时读取和（或）修改同一数据的情况。若对并发操作不加控制就可能会存取和存储不正确的数据，破坏数据库的一致性。所以数据库管理系统必须提供并发控制机制。
并发操作一般可能带来以下几种问题。为说明问题，先来准备一个例子，假设现在有一个账户表 TBL_BANK_ACCOUNT。
CREATE TABLE TBL_BANK_ACCOUNT（ AccountId CHAR(4) NOT NULL, -- 银行账号 Username NVARCHAR(63) NOT NULL, -- 用户名 Balance BIGINT NOT NULL -- 余额 ) INSERT INTO TBL_BANK_ACCOUNT VALUES (&#39;9555&#39;, &#39;小明&#39;, 1000) -- 北京分行账号 INSERT INTO dbo.BankAccount VALUES (&#39;9556&#39;, &#39;小明&#39;, 2000) -- 上海分行账号 脏读（Dirty reads） 一个事务读到另一个事务未提交的更新数据。
事务 1 取款事务 事务 2 工资转账事务 开始事务 开始事务 查询余额 1000 元 取出 100 变为 900 查询余额为 900 异常发生，事务回滚，余额恢复为 1000 汇入工资 2000 元，余额为 2900 提交事务，最终余额 2900，损失了 100 不可重复读（Non-Repeatable Reads） 在同一个事务内，读取表中的某一行记录，多次读取的结果不同。与幻读区别的重点在于修改，同样的条件，已经读取过的数据，再次读取出来和上一次的值不一样。
事务 1 工资计算 事务 2 汇款和通知 开始事务 开始事务 查询工资 2000 元，通知银行汇款 2000 增加加班费 6000 元 提交事务 再次查询工资应发 8000 元，邮件通知员工本月发了 8000 元 提交事务 幻读(Phantom Reads) 一个事务读到另一个事务已提交的新插入的数据,导致前后不一致。与不可重复读有点类似，都是两次读取。区别的重点在于增加或者删除。
事务 1 加班录入 事务 2 加班天数统计，计算加班费 开始事务 开始事务 统计员工小明加班 3 天 通知银行发 3 天的加班费 增加一天加班数据 提交事务 再次统计加班天数，是 4 天，通知小明发了 4 天的加班费 提交事务 事务隔离级别 事务隔离级别(Transaction Isolation Level)就是对事务并发控制的等级。标准组织 ANSI 定义了四个隔离级别，读未提交 Read uncommitted、读已提交 Read committed、可重复读 Repeatable read、串行化(序列化)Serializable，这四个级别严格程度越来越高，同时并发性能越来越低。
读未提交 Read uncommitted 一个事务在执行过程中可以看到其他事务没有提交的记录。
读已提交 Read committed 只能读已提交的数据。但是读取的数据可以被其他事务修改，这样也就会导致不可重复读。
可重复读 Repeatable read 所有被 Select 获取的数据都不能被修改。
序列化 Serializable 所有事务一个接一个的执行。
数据库并发问题还有常说的第一类更新丢失、第二类更新丢失，为减少概念复杂度，在这里没有列出来。
各个隔离级别和问题对应，√: 可能出现，×: 不会出现
脏读 不可重复读 幻读 Read uncommitted √ √ √ Read committed × √ √ Repeatable read × × √ Serializable × × × Oracle 和 SqlServer 默认隔离级别是读已提交，MySql 默认隔离级别是可重复读。
Oracle 只支持 READ COMMITTED 和 SERIALIZABLE 这两种标准隔离级别，另外增加了一个非标准的“只读(read-only)”隔离级别。顺便提一句，他的 Serializable 隔离级别，并不真正阻塞事务的执行（更深层次的理解另外单说）。
为避免幻读和不可重复读问题，一般是在一个事务里确保只读取数据一次，而不是提高事务的隔离级别。 况且 Oracle 也没法设置 Repeatable read。
事务传播行为 PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。Spring 默认的事务传播行为。 PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。 PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。 PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。 PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与 PROPAGATION_REQUIRED 类似的操作。 嵌套事务 嵌套是子事务套在父事务中执行，子事务是父事务的一部分，在进入子事务之前，父事务建立一个回滚点，叫 save point，然后执行子事务，这个子事务的执行也算是父事务的一部分，然后子事务执行结束，父事务继续执行。重点就在于那个 save point。看几个问题就明了了：
如果子事务回滚，会发生什么？ 父事务会回滚到进入子事务前建立的 save point，然后尝试其他的事务或者其他的业务逻辑，父事务之前的操作不会受到影响，更不会自动回滚。
如果父事务回滚，会发生什么？ 父事务回滚，子事务也会跟着回滚！为什么呢，因为父事务结束之前，子事务是不会提交的，我们说子事务是父事务的一部分，正是这个道理。那么：
事务的提交，是什么情况？ 是父事务先提交，然后子事务提交，还是子事务先提交，父事务再提交？答案是第二种情况，还是那句话，子事务是父事务的一部分，由父事务统一提交。
只读事务 readOnly 概念：从这一点设置的时间点开始到这个事务结束的过程中，其他事务所提交的数据，该事务将看不见。
应用场合：
如果你一次执行单条查询语句，则没有必要启用事务支持，数据库默认支持 SQL 执行期间的读一致性； 如果你一次执行多条查询语句，例如统计查询，报表查询，在这种场景下，多条查询 SQL 必须保证整体的读一致性，否则，在前条 SQL 查询之后，后条 SQL 查询之前，数据被其他用户改变，则该次整体的统计查询将会出现读数据不一致的状态，此时，应该启用事务支持。 总结：
readonly 并不是所有数据库都支持的，不同的数据库下会有不同的结果。 设置了 readonly 后，connection 都会被赋予 readonly，效果取决于数据库的实现。 在 ORM 中，设置了 readonly 会赋予一些额外的优化，例如在 Hibernate 中，会被禁止 flush 等。 由于只读事务不存在数据的修改，因此数据库将会为只读事务提供一些优化手段，例如 Oracle 对于只读事务，不启动回滚段，不记录回滚 log。 Spring 声明式事务 Spring 提供了编程式事务和声明式事务两种机制。为便于理解，简单回顾下 JDBC 和 Hibernate 的事务管理方式。
JDBC 方式： Connection conn = DataSourceUtils.getConnection(); //开启事务 conn.setAutoCommit(false); try { Object retVal = callback.doInConnection(conn); conn.commit(); //提交事务 return retVal; }catch (Exception e) { conn.rollback();//回滚事务 throw e; }finally { conn.close(); } Hibernate 方式： Session session = null; Transaction transaction = null; try { session = factory.openSession(); //开启事务 transaction = session.beginTransaction(); transation.begin(); session.save(user); transaction.commit();//提交事务 } catch (Exception e) { transaction.rollback();//回滚事务 return false; }finally{ session.close(); } 看下 Spring 编程式方式：
//1.获取事务管理器 PlatformTransactionManager txManager =ctx.getBean(&#34;txManager&#34;); //2.定义事务属性 DefaultTransactionDefinition td = new DefaultTransactionDefinition(); td.setIsolationLevel(TransactionDefinition.ISOLATION_READ_COMMITTED); //3开启事务,得到事务状态 TransactionStatus status = txManager.getTransaction(td); try { //4.执行数据库操作 jdbcTempate.queryForInt(&#34;select count(*) from tbl_doc&#34;); //5、提交事务 txManager.commit(status); }catch (Exception e) { //6、回滚事务 txManager.rollback(status); } 可以看到，以上几种方式都比较复杂，需要我们自己处理事务，要做的事情比较多。而 Spring 的声明式事务使用简单，它支持注解和 xml 配置，这里以注解为例。
@Transactional Spring 声明式事务的使用，一切都落在注解**@Transactional**上。
先看一个简单的例子，在实现类的加注解，实现事务控制。
&lt;!-- the service class that we want to make transactional --&gt; @Transactional public class DefaultFooService implements FooService { Foo getFoo(String fooName); Foo getFoo(String fooName, String barName); void insertFoo(Foo foo); void updateFoo(Foo foo); } 使用方法 @Transactional 可用于接口、接口方法、实现类以及类方法上。放在接口或类上，相当于为此接口或类下所有的 public 方法都加了这样一个注解。 Spring 团队的建议是你在具体的类（或类的方法）上使用 @Transactional 注解，而不要使用在类所要实现的任何接口上。你当然可以在接口上使用 @Transactional 注解，但是这将只能当你设置了基于接口的代理时它才生效。因为注解是不能继承的，这就意味着如果你正在使用基于类的代理时，那么事务的设置将不能被基于类的代理所识别，而且对象也将不会被事务代理所包装（将被确认为严重的）。因此，请接受 Spring 团队的建议并且在具体的类上使用@Transactional 注解。 @Transactional 注解应该只被应用到 public 的方法上。 如果你在 protected、private 或者 package-visible 的方法上使用，它也不会报错，也不会生效。 方法的@Transactional 会覆盖类上面声明的事务，也就是方法上的优先级高。 传播行为（Propagation） 所谓事务传播行为就是多个事务方法相互调用时，事务如何在这些方法间传播。Spring 支持 7 种事务传播行为：
PROPAGATION_REQUIRED 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY 使用当前的事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则开启一个新的事务。PROPAGATION_NESTED 开始一个 &ldquo;嵌套的&rdquo; 事务, 它是已经存在事务的一个真正的子事务. 潜套事务开始执行时, 它将取得一个 savepoint. 如果这个嵌套事务失败, 我们将回滚到此 savepoint. 潜套事务是外部事务的一部分, 只有外部事务结束后它才会被提交. 嵌套事务回滚不影响外部事务，但外部事务回滚将导致嵌套事务回滚。 使用嵌套事务需要 JDBC3.0 并且事务管理器开启嵌套事务（常用的 JpaTransactionManager 和 HibernateTransactionManager 默认是不开启的），如果没有开启，运行时将抛出异常。 举例，现有用户和地址管理，假如每增加一个新用户就需要自动增加一个与此用户相关的地址（这例子真挫，至今没有见到过这样的需求）。那么代码大致是这个样子：
//用户管理类 public class UserService { @Resource private UserDao userDao; /** 地址管理类 */ @Resource private AddressService addressService; @Transactional public void save(User user){ //执行sql保存用户信息 userDao.add(user); Address address=new Address();//设置地址信息 //执行sql保存地址信息 addressService.save(address); } } //测试类 public class ApplicationTest { @Resource private UserService userService; @Test public void transactionalTest() { User user = new User(); user.setUsername(&#34;Test-001&#34;); userService.save(user); } } @Transactional 注解加在 UserService.save 和 AddressService.save 两个方法上。
具体的事务开启和关闭流程，设置 spring 的日志级别为 debug 后，运行，可看到类似于这面这样的日志。这里使用了 Spring data jpa，打印的是 JpaTransactionManager 的日志。UserServices 使用的传播行为是 REQUIRED，AddressService 使用 REQUIRES_NEW。
- Creating new transaction with name [UserService.save]:PROPAGATION_REQUIRED,ISOLATION_DEFAULT; &#39;&#39; - Opened new EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@16602333] for JPA transaction - Exposing JPA transaction as JDBC transaction [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@2dd4a7a9] - Found thread-bound EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@16602333] for JPA transaction - Participating in existing transaction - Found thread-bound EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@16602333] for JPA transaction - Suspending current transaction, creating new transaction with name [AddressService.save] - Opened new EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@28b7646] for JPA transaction - Exposing JPA transaction as JDBC transaction [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@40239b34] - Found thread-bound EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@28b7646] for JPA transaction - Participating in existing transaction - Initiating transaction commit - Committing JPA transaction on EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@28b7646] - Closing JPA EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@28b7646] after transaction - Closing JPA EntityManager - Resuming suspended transaction after completion of inner transaction - Initiating transaction commit - Committing JPA transaction on EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@16602333] - Closing JPA EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@16602333] after transaction `}),e.add({id:28,href:"/bits-pieces/linux/regular-expressions/",title:"Regular Expressions",content:`正则表达式从入门到放弃 首先来看几个问题：
假设有一个字符串“a b c”(中间是一个空格)，想实现按空格分割成一个数组[&ldquo;a&rdquo;,&ldquo;b&rdquo;,&ldquo;c&rdquo;]，用 Java 或 JavaScript 代码如何实现。 原始数组改成&quot;a b c&quot;(中间是 N 个空格)，仍分割成数组[&ldquo;a&rdquo;,&ldquo;b&rdquo;,&ldquo;c&rdquo;]，如何实现。 @Test public void testSplit() { String dotStr = &#34;a.b.c&#34;; assertEquals(dotStr.split(&#34;.&#34;).length, 0); assertEquals(dotStr.split(&#34;\\\\.&#34;).length, 3); String spaceStr=&#34;a b c&#34;;//a与b之间两个空格,b与c之间一个空格 assertEquals(spaceStr.split(&#34; &#34;).length, 4);//一个空格 assertEquals(spaceStr.split(&#34; +&#34;).length, 3);//一个或多个空格 assertEquals(&#34;a b c&#34;.split(&#34; +&#34;).length, 3);//一个或多个空格 assertEquals(&#34;a b c&#34;.split(&#34; +&#34;).length, 3);//一个或多个空格 //顺便提一句,与正则无关,注意下面这个结果,这是Java的split方法自己处理的 assertEquals(&#34;a b c &#34;.split(&#34; &#34;).length, 3);//split会去除最后为空的结果 assertEquals(&#34; a b c&#34;.split(&#34; &#34;).length, 4);//split不会去除前面为空的结果 } 以上就是一个正则的简单应用，其实平时工作中除了编程我们也会经常用到正则，比如搜索所有 Word 文档（*.doc）,在文本编辑器中搜索和替换文字等等。正则表达式经过数年的发展，已经逐渐从模糊而深奥的数学概念，发展成为在计算机各类工具和软件包应用中的主要功能，成为人们工作中的一个利器。
什么是正则表达式 正则表达式（Regular Expression，regex、regexp，以下简称正则）是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。
完整的正则表达式由两种字符构成，特殊字符（又译元字符）和普通文字。如果把正则表达式想象成普通的语言，普通文字相当于语言中的单词，而元字符相当于语法。就像一门语言一样，正则是烦琐而强大的，学会之后的应用会让你除了提高效率外，会给你带来绝对的成就感。只要坚持去学，一定会放弃的。
正则引擎 引擎就相当于语言的编译器，解释器，用来对正则进行语法分析。不同的引擎决定了某个正则能否匹配、在何处匹配，以及匹配成功或报告失败的速度，另外知道正则表达式引擎是如何工作的有助于理解为何某个正则表达式在一个平台好用，换个平台就不好使了。
正则引擎主要可以分为两大类：一种是 DFA，一种是 NFA。先别管这两个的含义，只需要知道这两个名字。这两种引擎都有了很长的历史，当中也由这两种引擎产生了很多变体。后来又出了一个 POSIX 标准，用来规范这种现象。DFA 是符合这种标准的，NFA 不符合，这样一来，主流的正则引擎又分为 3 类：DFA，传统型 NFA，POSIX NFA。
关于 DFA 和 NFA 的详细区别，在这里先不提了，因为正则本身就是一个很难懂的语言，一下子提这么多怕大家真的放弃了。但是要了解一点，不同的引擎不同的写法，速度是不一样的，如果对性能要求高的话，还是需要了解引擎的实现方式。Java 和 JavaScript 都是 NFA 类型。除去引擎的不同，不同的语言对正则的实现也有差异，所以下面所有的语法和实例，多以 Java 为主，尽量兼顾 JavaScript，不考虑 Python、C++、Swift 等其他语言。
基础语法 元字符 说明 ^ 匹配输入字符串开始的位置。 $ 匹配输入字符串结尾的位置。 _ 零次或多次匹配前面的字符或子表达式。例如，zo_ 匹配&quot;z&quot;和&quot;zoo&quot;。* 等效于 {0,}。 + 一次或多次匹配前面的字符或子表达式。例如，&ldquo;zo+&ldquo;与&quot;zo&quot;和&quot;zoo&quot;匹配，但与&quot;z&quot;不匹配。+ 等效于 {1,}。 ? 零次或一次匹配前面的字符或子表达式。例如，&ldquo;do(es)?&ldquo;匹配&quot;do&quot;或&quot;does&quot;中的&quot;do&rdquo;。? 等效于 {0,1}。 {n} n 是非负整数。正好匹配 n 次。例如，&ldquo;o{2}&ldquo;与&quot;Bob&quot;中的&quot;o&quot;不匹配，但与&quot;food&quot;中的两个&quot;o&quot;匹配。 {n,} n 是非负整数。至少匹配 n 次。例如，&ldquo;o{2,}&ldquo;不匹配&quot;Bob&quot;中的&quot;o&rdquo;，而匹配&quot;foooood&quot;中的所有 o。&ldquo;o{1,}&ldquo;等效于&quot;o+&quot;。&ldquo;o{0,}&ldquo;等效于&quot;o*&quot;。 {n,m} M 和 n 是非负整数，其中 n &lt;= m。匹配至少 n 次，至多 m 次。注意：您不能将空格插入逗号和数字之间。 ? 当此字符紧随任何其他限定符（*、+、?、{n}、{n,}、{n,m}）之后时，匹配模式是&quot;非贪心的&rdquo;。&ldquo;非贪心的&quot;模式匹配搜索到的、尽可能短的字符串，而默认的&quot;贪心的&quot;模式匹配搜索到的、尽可能长的字符串。例如，在字符串&quot;oooo&quot;中，&ldquo;o+?&ldquo;只匹配单个&quot;o&rdquo;，而&quot;o+&ldquo;匹配所有&quot;o&rdquo;。 . 匹配除&rdquo;\\r\\n&quot;之外的任何单个字符。若要匹配包括&rdquo;\\r\\n&quot;在内的任意字符，请使用诸如&rdquo;[\\s\\S]&ldquo;之类的模式。 (pattern) 匹配 pattern 并捕获该匹配的子表达式。可以使用 $0…$9 属性从结果&quot;匹配&quot;集合中检索捕获的匹配。若要匹配括号字符 ( )，请使用&rdquo;(&ldquo;或者&rdquo;)&quot;。 x│y 匹配 x 或 y。例如&rsquo;(z│f)ood&rsquo; 匹配&quot;zood&quot;或&quot;food&rdquo;。 [xyz] 字符集。匹配包含的任一字符。例如，&rdquo;[abc]&ldquo;匹配&quot;plain&quot;中的&quot;a&rdquo;。 [^xyz] 反向字符集。匹配未包含的任何字符。例如，&rdquo;[^abc]&ldquo;匹配&quot;plain&quot;中&quot;p&rdquo;，&ldquo;l&rdquo;，&ldquo;i&rdquo;，&ldquo;n&rdquo;。 [a-z] 字符范围。匹配指定范围内的任何字符。例如，&rdquo;[a-z]&ldquo;匹配&quot;a&quot;到&quot;z&quot;范围内的任何小写字母。 [^a-z] 反向范围字符。匹配不在指定的范围内的任何字符。例如，&rdquo;[^a-z]&ldquo;匹配任何不在&quot;a&quot;到&quot;z&quot;范围内的任何字符。 \\b 匹配一个字边界，即字与空格间的位置。例如，&ldquo;er\\b&quot;匹配&quot;never&quot;中的&quot;er&rdquo;，但不匹配&quot;verb&quot;中的&quot;er&rdquo;。 \\B 非字边界匹配。&ldquo;er\\B&quot;匹配&quot;verb&quot;中的&quot;er&rdquo;，但不匹配&quot;never&quot;中的&quot;er&rdquo;。 \\d 数字字符匹配。等效于 [0-9]。 \\D 非数字字符匹配。等效于 [^0-9]。 \\f 换页符匹配。等效于 \\x0c 和 \\cL。 \\n 换行符匹配。等效于 \\x0a 和 \\cJ。 \\r 匹配一个回车符。等效于 \\x0d 和 \\cM。 \\s 匹配任何空白字符，包括空格、制表符、换页符等。 \\S 匹配任何非空白字符。 \\t 制表符匹配。 \\w 匹配任何字类字符，包括下划线。与&rdquo;[A-Za-z0-9_]&ldquo;等效。 \\W 与任何非单词字符匹配。与&rdquo;[^a-za-z0-9_]&ldquo;等效。 运算符优先级 正则表达式从左到右进行计算，并遵循优先级顺序，这与算术表达式非常类似。相同优先级的从左到右进行运算，不同优先级的运算先高后低。下表从最高到最低说明了各种正则表达式运算符的优先级顺序.
`}),e.add({id:29,href:"/bits-pieces/categories/",title:"Categories",content:""}),e.add({id:30,href:"/bits-pieces/tags/",title:"Tags",content:""})})()