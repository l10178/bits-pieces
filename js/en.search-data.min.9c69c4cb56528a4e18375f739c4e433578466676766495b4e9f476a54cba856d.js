'use strict';(function(){const indexCfg={};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create(indexCfg);window.geekdocSearchIndex=index;index.add({'id':0,'href':'/bits-pieces/java/','title':"Javas",'content':""});index.add({'id':1,'href':'/bits-pieces/java/jvm/','title':"Java进程内存分析",'content':"故事背景：\n一个 K8S Pod，里面只有一个 Java 进程，K8S request 和 limit memory 都是 2G，Java 进程核心参数包括：-XX:+UseZGC -Xmx1024m -Xms768m -XX:SoftMaxHeapSize=512m。\n服务启动一段时间后，查看 Grafana 监控数据，Pod 内存使用量约 1.5G，JVM 内存使用量约 500M，通过 jvm dump 分析没有任何大对象，运行三五天后出现 ContainerOOM。\n首先区分下 ContainerOOM 和 JvmOOM，ContainerOOM 是 Pod 内存不够，Java 向操作系统申请内存时内存不足导致。\n问题来了：\n Pod 2G 内存，JVM 设置了 Xmx 1G，已经预留了 1G 内存，为什么还会 ContainerOOM，这预留的 1G 内存被谁吃了。 正常情况下（无 ContainerOOM），Grafana 看到的监控数据，Pod 内存使用量 1.5G， JVM 内存使用量 500M，差别为什么这么大。 Grafana 看到的监控数据，内存使用量、提交量各是什么意思，这些值是怎么算出来的，和 Pod 进程中如何对应，为什么提交量一直居高不小。  Grafana 监控图。\n\n统计指标 Pod 内存使用量统计的指标是 container_memory_working_set_bytes：\n container_memory_usage_bytes = container_memory_rss + container_memory_cache + kernel memory container_memory_working_set_bytes = container_memory_usage_bytes - total_inactive_file（未激活的匿名缓存页）  container_memory_working_set_bytes 是容器真实使用的内存量，也是资源限制 limit 时的 OOM 判断依据。\n另外注意 cgroup 版本差异： container_memory_cache reflects cache (cgroup v1) or file (cgroup v2) entry in memory.stat.\nJVM 内存使用量统计的指标是 jvm_memory_bytes_used： heap、non-heap 以及其他 真实用量总和。下面解释其他。\n对比一下 top 命令，使用 top 命令看一下 Java 进程真正占了多少。\ntop -p $(pgrep java) # 注意下面的数据和截图不是同一时间的 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 7 root 20 0 58.2g 1.6g 1.0g S 17.3 2.3 659:42.46 java VIRT：virtual memory usage 虚拟内存\n 进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等 假如进程申请 100m 的内存，但实际只使用了 10m，那么它会增长 100m，而不是实际的使用量  RES：resident memory usage 常驻内存\n 进程当前使用的内存大小，但不包括被换出到交换区的部分 包含其他进程的共享 如果申请 100m 的内存，实际使用 10m，它只增长 10m，与 VIRT 相反 关于库占用内存的情况，它只统计加载的库文件所占内存大小  SHR：shared memory 共享内存\n 除了自身进程的共享内存，也包括其他进程的共享内存 虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小 计算某个进程所占的物理内存大小公式：RES – SHR。（JVM 的内存使用量等于 RES-SHR）  container_memory_working_set_bytes 与 Top RES 相等吗。\n为什么 container_memory_working_set_bytes 大于 top RES:\n因为 container_memory_working_set_bytes 包含 container_memory_cache，这涉及到 Linux 缓存机制，延伸阅读：https://zhuanlan.zhihu.com/p/449630026。遇到这种场景一般都是文件操作较多，可优先排除文件类操作。\n为什么 container_memory_working_set_bytes 小于 top RES:\n主要还是算法和数据来源不一样，top 的 RES=Code + Data，有些服务 Data 比较大。 当然实际测试会发现 RES!=Code + Data ，延伸阅读：https://liam.page/2020/07/17/memory-stat-in-TOP/\n另外可能看到的现象，top、granfana、docker stats、JMX 看到的使用量怎么都不一样，都是因为他们统计的维度不一样。\n所以通过 top 命令看到的数据不一定是真实的，container_memory_working_set_bytes 指标来自 cadvisor，cadvisor 数据来源 cgroup，可以查看以下文件获取真实的内存情况。\n# 线上老版本，cgroup v1 ll /sys/fs/cgroup/memory/ total 0 drwxr-xr-x. 2 root root 0 Dec 24 19:22 ./ dr-xr-xr-x. 13 root root 340 Dec 24 19:22 ../ -rw-r--r--. 1 root root 0 Dec 24 19:22 cgroup.clone_children --w--w--w-. 1 root root 0 Dec 24 19:22 cgroup.event_control -rw-r--r--. 1 root root 0 Dec 24 19:22 cgroup.procs -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.failcnt --w-------. 1 root root 0 Dec 24 19:22 memory.force_empty -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.failcnt -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.limit_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.max_usage_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.slabinfo -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.tcp.failcnt -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.tcp.limit_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.tcp.max_usage_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.tcp.usage_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.kmem.usage_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.limit_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.max_usage_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.memsw.failcnt -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.memsw.limit_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.memsw.max_usage_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.memsw.usage_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.move_charge_at_immigrate -r--r--r--. 1 root root 0 Dec 24 19:22 memory.numa_stat -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.oom_control ----------. 1 root root 0 Dec 24 19:22 memory.pressure_level -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.soft_limit_in_bytes -r--r--r--. 1 root root 0 Dec 24 19:22 memory.stat -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.swappiness -r--r--r--. 1 root root 0 Dec 24 19:22 memory.usage_in_bytes -rw-r--r--. 1 root root 0 Dec 24 19:22 memory.use_hierarchy -rw-r--r--. 1 root root 0 Dec 24 19:22 notify_on_release -rw-r--r--. 1 root root 0 Dec 24 19:22 tasks # 线下新版本，cgroup v2 ll /sys/fs/cgroup/memory.* -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.current -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.events -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.events.local -rw-r--r-- 1 root root 0 Jan 7 11:50 /sys/fs/cgroup/memory.high -rw-r--r-- 1 root root 0 Jan 7 11:50 /sys/fs/cgroup/memory.low -rw-r--r-- 1 root root 0 Jan 7 11:50 /sys/fs/cgroup/memory.max -rw-r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.min -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.numa_stat -rw-r--r-- 1 root root 0 Jan 7 11:50 /sys/fs/cgroup/memory.oom.group -rw-r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.pressure -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.stat -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.swap.current -r--r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.swap.events -rw-r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.swap.high -rw-r--r-- 1 root root 0 Jan 6 16:25 /sys/fs/cgroup/memory.swap.max JVM 关于使用量和提交量的解释。\nUsed Size：The used space is the amount of memory that is currently occupied by Java objects. 当前实际真的用着的内存，每个 bit 都对应了有值的。\nCommitted Size：The committed size is the amount of memory guaranteed to be available for use by the Java virtual machine.\n操作系统向 JVM 保证可用的内存大小，或者说 JVM 向操作系统已经要的内存。站在操作系统的角度，就是已经分出去（占用）的内存，保证给 JVM 用了，其他进程不能用了。 由于操作系统的内存管理是惰性的，对于已申请的内存虽然会分配地址空间，但并不会直接占用物理内存，真正使用的时候才会映射到实际的物理内存，所以 committed \u0026gt; res 也是很可能的。\nJava 进程内存分析 Pod 的内存使用量 1.5G，都包含哪些。\nkernel memory 为 0，Cache 约 1100M，rss 约 650M，inactive_file 约 200M。可以看到 Cache 比较大，因为这个服务比较特殊有很多文件操作。\n# 这个数据和上面的1.5G不是同时的。 cat /sys/fs/cgroup/memory/memory.stat cache 1455861760 rss 685862912 rss_huge 337641472 mapped_file 504979456 swap 0 inactive_anon 805306368 active_anon 685817856 inactive_file 299671552 active_file 350883840 total_rss 685862912 total_rss_huge 337641472 total_mapped_file 504979456 total_inactive_file 299671552 total_active_file 350883840 # cgroup v2 变量变了 cat /sys/fs/cgroup/memory.stat anon 846118912 file 2321530880 kernel_stack 10895360 pagetables 15523840 percpu 0 sock 1212416 shmem 1933574144 file_mapped 1870290944 file_dirty 12288 file_writeback 0 swapcached 0 anon_thp 0 file_thp 0 shmem_thp 0 inactive_anon 2602876928 active_anon 176771072 inactive_file 188608512 active_file 199348224 unevictable 0 slab_reclaimable 11839688 slab_unreclaimable 7409400 slab 19249088 workingset_refault_anon 0 workingset_refault_file 318 workingset_activate_anon 0 workingset_activate_file 95 workingset_restore_anon 0 workingset_restore_file 0 workingset_nodereclaim 0 pgfault 2563565 pgmajfault 15 pgrefill 14672 pgscan 25468 pgsteal 25468 pgactivate 106436 pgdeactivate 14672 pglazyfree 0 pglazyfreed 0 thp_fault_alloc 0 thp_collapse_alloc 0 通过 Java 自带的 Native Memory Tracking 看下内存提交量。\n# Java启动时先打开NativeMemoryTracking，默认是关闭的。注意不要在生产环境长期开启，有性能损失 java -XX:NativeMemoryTracking=detail -jar # 查看详情 jcmd $(pgrep java) VM.native_memory detail scale=MB 通过 Native Memory Tracking 追踪到的详情大致如下，关注其中每一项 committed 值。\nNative Memory Tracking: (Omitting categories weighting less than 1MB) Total: reserved=68975MB, committed=1040MB - Java Heap (reserved=58944MB, committed=646MB) (mmap: reserved=58944MB, committed=646MB) - Class (reserved=1027MB, committed=15MB) (classes #19551) #加载类的个数 ( instance classes #18354, array classes #1197) (malloc=3MB #63653) (mmap: reserved=1024MB, committed=12MB) ( Metadata: ) ( reserved=96MB, committed=94MB) ( used=93MB) ( waste=0MB =0.40%) ( Class space:) ( reserved=1024MB, committed=12MB) ( used=11MB) ( waste=1MB =4.63%) - Thread (reserved=337MB, committed=37MB) (thread #335) #线程的个数 (stack: reserved=336MB, committed=36MB) (malloc=1MB #2018) - Code (reserved=248MB, committed=86MB) (malloc=6MB #24750) (mmap: reserved=242MB, committed=80MB) - GC (reserved=8243MB, committed=83MB) (malloc=19MB #45814) (mmap: reserved=8224MB, committed=64MB) - Compiler (reserved=3MB, committed=3MB) (malloc=3MB #2212) - Internal (reserved=7MB, committed=7MB) (malloc=7MB #31683) - Other (reserved=18MB, committed=18MB) (malloc=18MB #663) - Symbol (reserved=19MB, committed=19MB) (malloc=17MB #502325) (arena=2MB #1) - Native Memory Tracking (reserved=12MB, committed=12MB) (malloc=1MB #8073) (tracking overhead=11MB) - Shared class space (reserved=12MB, committed=12MB) (mmap: reserved=12MB, committed=12MB) - Module (reserved=1MB, committed=1MB) (malloc=1MB #4996) - Synchronization (reserved=1MB, committed=1MB) (malloc=1MB #2482) - Metaspace (reserved=97MB, committed=94MB) (malloc=1MB #662) (mmap: reserved=96MB, committed=94MB) - Object Monitors (reserved=8MB, committed=8MB) (malloc=8MB #39137) 一图解千愁，盗图。\n\n  Heap Heap 是 Java 进程中使用量最大的一部分内存，是最常遇到内存问题的部分，Java 也提供了很多相关工具来排查堆内存泄露问题，这里不详细展开。Heap 与 RSS 相关的几个重要 JVM 参数如下： Xms：Java Heap 初始内存大小。(目前我们用的百分比控制，MaxRAMPercentage) Xmx：Java Heap 的最大大小。(InitialRAMPercentage) XX:+UseAdaptiveSizePolicy：是否开启自适应大小策略。开启后，JVM 将动态判断是否调整 Heap size，来降低系统负载。\n  Metaspace Metaspace 主要包含方法的字节码，Class 对象，常量池。一般来说，记载的类越多，Metaspace 使用的内存越多。与 Metaspace 相关的 JVM 参数有: XX:MaxMetaspaceSize: 最大的 Metaspace 大小限制【默认无限制】 XX:MetaspaceSize=64M: 初始的 Metaspace 大小。如果 Metaspace 空间不足，将会触发 Full GC。 类空间占用评估，给两个数字可供参考：10K 个类约 90M，15K 个类约 100M。 什么时候回收：分配给一个类的空间，是归属于这个类的类加载器的，只有当这个类加载器卸载的时候，这个空间才会被释放。释放 Metaspace 的空间，并不意味着将这部分空间还给系统内存，这部分空间通常会被 JVM 保留下来。 扩展：参考资料中的Java Metaspace详解，这里完美解释 Metaspace、Compressed Class Space 等。\n  Thread NMT 中显示的 Thread 部分内存与线程数与 -Xss 参数成正比，一般来说 committed 内存等于 Xss*线程数 。\n  Code JIT 动态编译产生的 Code 占用的内存。这部分内存主要由-XX:ReservedCodeCacheSize 参数进行控制。\n  Internal Internal 包含命令行解析器使用的内存、JVMTI、PerfData 以及 Unsafe 分配的内存等等。 需要注意的是，Unsafe_AllocateMemory 分配的内存在 JDK11 之前，在 NMT 中都属于 Internal，但是在 JDK11 之后被 NMT 归属到 Other 中。\n  Symbol Symbol 为 JVM 中的符号表所使用的内存，HotSpot 中符号表主要有两种：SymbolTable 与 StringTable。 大家都知道 Java 的类在编译之后会生成 Constant pool 常量池，常量池中会有很多的字符串常量，HotSpot 出于节省内存的考虑，往往会将这些字符串常量作为一个 Symbol 对象存入一个 HashTable 的表结构中即 SymbolTable，如果该字符串可以在 SymbolTable 中 lookup（SymbolTable::lookup）到，那么就会重用该字符串，如果找不到才会创建新的 Symbol（SymbolTable::new_symbol）。 当然除了 SymbolTable，还有它的双胞胎兄弟 StringTable（StringTable 结构与 SymbolTable 基本是一致的，都是 HashTable 的结构），即我们常说的字符串常量池。平时做业务开发和 StringTable 打交道会更多一些，HotSpot 也是基于节省内存的考虑为我们提供了 StringTable，我们可以通过 String.intern 的方式将字符串放入 StringTable 中来重用字符串。\n  Native Memory Tracking Native Memory Tracking 使用的内存就是 JVM 进程开启 NMT 功能后，NMT 功能自身所申请的内存。\n  观察上面几个区域的分配，没有明显的异常。\nNMT 追踪到的 是 Committed，不一定是 Used，NMT 和 cadvisor 没有找到必然的对应的关系。可以参考 RSS，cadvisor 追踪到 RSS 是 650M，JVM Used 是 500M，还有大约 150M 浮动到哪里去了。\n因为 NMT 只能 Track JVM 自身的内存分配情况，比如：Heap 内存分配，direct byte buffer 等。无法追踪的情况主要包括：\n 使用 JNI 调用的一些第三方 native code 申请的内存，比如使用 System.Loadlibrary 加载的一些库。 标准的 Java Class Library，典型的，如文件流等相关操作（如：Files.list、ZipInputStream 和 DirectoryStream 等）。主要涉及到的调用是 Unsafe.allocateMemory 和 java.util.zip.Inflater.init(Native Method)。  怎么追踪 NMT 追踪不到的其他内存，目前是安装了 jemalloc 内存分析工具，他能追踪底层内存的分配情况输出报告。\n通过 jemalloc 内存分析工具佐证了上面的结论，Unsafe.allocateMemory 和 java.util.zip.Inflater.init 占了 30%，基本吻合。\n\n启动 arthas 查看下类调用栈，在 arthas 里执行以下命令：\n# 先设置unsafe true options unsafe true # 这个没有 stack sun.misc.Unsafe allocateMemory # 这个有 stack jdk.internal.misc.Unsafe allocateMemory stack java.util.zip.Inflater inflate 通过上面的命令，能看到 MongoDB 和 netty 一直在申请使用内存。注意：早期的 mongodb client 确实有无法释放内存的 bug，但是在我们场景，长期观察会发现内存申请了逐渐释放了，没有持续增长。回到开头的 ContainerOOM 问题，可能一个原因是流量突增，MongoDB 申请了更多的内存导致 OOM，而不是因为内存不释放。\nts=2022-12-29 21:20:01;thread_name=ForkJoinPool.commonPool-worker-1;id=22;is_daemon=true;priority=1;TCCL=jdk.internal.loader.ClassLoaders$AppClassLoader@1d44bcfa @jdk.internal.misc.Unsafe.allocateMemory() at java.nio.DirectByteBuffer.\u0026lt;init\u0026gt;(DirectByteBuffer.java:125) at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:332) at sun.nio.ch.Util.getTemporaryDirectBuffer(Util.java:243) at sun.nio.ch.NioSocketImpl.tryWrite(NioSocketImpl.java:394) at sun.nio.ch.NioSocketImpl.implWrite(NioSocketImpl.java:413) at sun.nio.ch.NioSocketImpl.write(NioSocketImpl.java:440) at sun.nio.ch.NioSocketImpl$2.write(NioSocketImpl.java:826) at java.net.Socket$SocketOutputStream.write(Socket.java:1035) at com.mongodb.internal.connection.SocketStream.write(SocketStream.java:99) at com.mongodb.internal.connection.InternalStreamConnection.sendMessage(InternalStreamConnection.java:426) at com.mongodb.internal.connection.UsageTrackingInternalConnection.sendAndReceive(UsageTrackingInternalConnection.java:99) at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection.sendAndReceive(DefaultConnectionPool.java:444) ……………………………… at com.mongodb.MongoClientExt$1.execute(MongoClientExt.java:42) at com.facishare.oms.thirdpush.dao.MongoDao.save(MongoDao.java:31) ……………………………… 总结 Java 进程内存占用：Total=heap + non-heap + 上面说的这个其他。\njemalloc jemalloc 是一个比 glibc malloc 更高效的内存池技术，在 Facebook 公司被大量使用，在 FreeBSD 和 FireFox 项目中使用了 jemalloc 作为默认的内存管理器。使用 jemalloc 可以使程序的内存管理性能提升，减少内存碎片。\n比如 Redis 内存分配默认使用的 jemalloc，早期版本安装 redis 是需要手动安装 jemalloc 的，现在 redis 应该是在编译期内置好了。\n原来使用 jemalloc 是为了分析内存占用，通过 jemalloc 输出当前内存分配情况，或者通过 diff 分析前后内存差，大概能看出内存都分给睡了，占了多少，是否有内存无法释放的情况。\n后来参考了这个文章，把 glibc 换成 jemalloc 带来性能提升，降低内存使用，决定一试。\nhow we’ve reduced memory usage without changing any code：https://blog.malt.engineering/java-in-k8s-how-weve-reduced-memory-usage-without-changing-any-code-cbef5d740ad\nDecreasing RAM Usage by 40% Using jemalloc with Python \u0026amp; Celery: https://zapier.com/engineering/celery-python-jemalloc/\n一个服务，运行一周，观察效果。\n使用 Jemalloc 之前： \n使用 Jemalloc 之后（同时调低了 Pod 内存）： \n注：以上结果未经生产长期检验。\n内存交还给操作系统 注意：下面的操作，生产环境不建议这么干。\n默认情况下，OpenJDK 不会主动向操作系统退还未用的内存（不严谨）。看第一张监控的图，会发现运行一段时间后，Pod 的内存使用量一直稳定在 80%\u0026ndash;90%不再波动。\n其实对于 Java 程序，浮动比较大的就是 heap 内存。其他区域 Code、Metaspace 基本稳定\n# 执行命令获取当前heap情况 jhsdb jmap --heap --pid $(pgrep java) #以下为输出 Attaching to process ID 7, please wait... Debugger attached successfully. Server compiler detected. JVM version is 17.0.5+8-LTS using thread-local object allocation. ZGC with 4 thread(s) Heap Configuration: MinHeapFreeRatio = 40 MaxHeapFreeRatio = 70 MaxHeapSize = 1287651328 (1228.0MB) NewSize = 1363144 (1.2999954223632812MB) MaxNewSize = 17592186044415 MB OldSize = 5452592 (5.1999969482421875MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 22020096 (21.0MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB) Heap Usage: ZHeap used 310M, capacity 710M, max capacity 1228M Java 内存不交还，几种情况：\n  Xms 大于实际需要的内存，比如我们服务设置了 Xms768M，但是实际上只需要 256，高峰期也就 512，到不了 Xms 的值也就无所谓归还。 \n  上面 jmap 的结果，可以看到 Java 默认的配置 MaxHeapFreeRatio=70，这个 70% Free 几乎很难达到。（另外注意 Xmx==Xms 的情况下这两个参数无效，因为他怎么扩缩都不会突破 Xms 和 Xmx 的限制）\nMinHeapFreeRatio = 40 空闲堆空间的最小百分比，计算公式为：HeapFreeRatio =(CurrentFreeHeapSize/CurrentTotalHeapSize) * 100，值的区间为0到100，默认值为 40。如果HeapFreeRatio \u0026lt; MinHeapFreeRatio，则需要进行堆扩容，扩容的时机应该在每次垃圾回收之后。 MaxHeapFreeRatio = 70 空闲堆空间的最大百分比，计算公式为：HeapFreeRatio =(CurrentFreeHeapSize/CurrentTotalHeapSize) * 100，值的区间为0到100，默认值为 70。如果HeapFreeRatio \u0026gt; MaxHeapFreeRatio，则需要进行堆缩容，缩容的时机应该在每次垃圾回收之后。   对于 ZGC，默认是交还给操作系统的。可通过 -XX:+ZUncommit -XX:ZUncommitDelay=300 这两个参数控制（不再使用的内存最多延迟 300s 归还给 OS，线下环境可以改小点）。\n经过调整后的服务，内存提交在 500\u0026ndash;800M 之间浮动，不再是一条直线。\n\n问题原因分析和调整 回到开头问题，通过上面分析，2G 内存，RSS 其实占用 600M，为什么最终还是 ContainerOOM 了。\n kernel memory 为 0，排除 kernel 泄漏的原因。下面的参考资料里介绍了 kernel 泄露的两种场景。 Cache 很大，说明文件操作多。搜了一下代码，确实有很多 InputStream 调用没有显式关闭，而且有的 InputSteam Root 引用在 ThreadLocal 里，ThreadLocal 只 init 未 remove。 但是，ThreadLocal 的引用对象是线程池，池不回收，所以这部分可能会无法关闭，但是不会递增，但是 cache 也不能回收。 优化办法：ThreadLocal 中对象是线程安全的，无数据传递，直接干掉 ThreadLocal；显式关闭 InputStream。运行一周发现 cache 大约比优化前低 200\u0026ndash;500M。 ThreadLocal 引起内存泄露是 Java 中很经典的一个场景，一定要特别注意。 一般场景下，Java 程序都是堆内存占用高，但是这个服务堆内存其实在 200-500M 之间浮动，我们给他分了 768M，从来没有到过这个值，所以调低 Xms。留出更多内存给 JNI 使用。 线下环境内存分配切换到 jemalloc，待长期观察效果。  经过上述调整以后： 线下环境 Pod 内存使用量由 1G 降到 600M 作用。线上环境内存使用量在 50%\u0026ndash;80%之间根据流量大小浮动，原来是 85% 居高不小。\n参考资料 Java 进程内存分布：https://cloud.tencent.com/developer/article/1666640 Java Metaspace 详解：https://www.javadoop.com/post/metaspace how we’ve reduced memory usage without changing any code：https://blog.malt.engineering/java-in-k8s-how-weve-reduced-memory-usage-without-changing-any-code-cbef5d740ad Spring Boot 引起的堆外内存泄漏排查及经验总结：https://tech.meituan.com/2019/01/03/spring-boot-native-memory-leak.html Pod 进程内存缓存分析: https://zhuanlan.zhihu.com/p/449630026 Linux 内存中的 Cache 真的能被回收么: https://cloud.tencent.com/developer/article/1115557 Linux kernel memory 导致的 POD OOM killed: https://www.cnblogs.com/yannwang/p/13287963.html cgroup 内存泄露问题: https://www.cnblogs.com/leffss/p/15019898.html\n"});index.add({'id':2,'href':'/bits-pieces/devops/cdr/','title':"使用Visual Studio Code搭建多用户远程IDE",'content':"Securing Visual Studio code-server, support multi-user.\n为 code-server（VS Code Web 版） 增加外部认证，并支持多用户，不同用户的 code-server 实例完全隔离。\n主要为了解决问题：\n  code-server 本身支持配置文件形式的用户名密码认证（截止目前，以后也许会改进）。所以引入了外部认证系统，Google、GitHub、 okta、CAS、Keycloak 等理论上都是支持的。\n  code-server 默认没有数据隔离，所以又加了一层 proxy，为每个用户创建一个（或多个）code-server 实例，以实现用户间的数据隔离。\n  使用开源 Auth Proxy，自己不需要实现复杂的登录流程了，比如 code flow with pkce 对大部分人来说读懂这个协议都很困难。\n  使用组件   keycloak\nRedhat 开源 IAM 系统，提供用户、组织服务，提供标准 OIDC。\n  oauth2-proxy\n认证代理，配合 keycloak 提供完整 OAuth2 Code Flow 认证流程。也可以试试 pomerium，看样子也不错。\n  架构图如下。\n核心逻辑 架构图简单解读，所有过程官方文档都有详细说明，都是配置，以官方配置为准。\n  keycloak 创建 client，使用 OIDC 协议，作为 oauth2-proxy 的 provider。\n  ingress(nginx) 使用 auth_request 指令拦截所有请求，从 oauth2-proxy 进行代理认证，配置可参考 oauth2-proxy auth_request 指导。\nnginx.ingress.kubernetes.io/auth-signin:https://$host/oauth2/start?rd=$escaped_request_uringinx.ingress.kubernetes.io/auth-url:https://$host/oauth2/auth  认证通过后，将用户名/ID 作为标识，通过 Http Header (举例如 X-Forwarded-Preferred-Username) 传入 upstream。\n  gateway(nginx) 从 Header 中获取用户标识，代理到此用户对应的 code-server 实例。\nlocation / { …… proxy_pass http://code-server-$http_x_forwarded_for_preferred_username; }   code-server 各个实例部署时，以免认证方式部署。\n  每个 code-server 实例挂载不同的存储，实现完全隔离。\n  "});index.add({'id':3,'href':'/bits-pieces/devops/mysql5.7to8.0/','title':"MySQL5.7升级至8.0",'content':"MySQL 5.7 升级至 8.0，程序适配以及踩坑记录。\n代码适配方案  mysql-connector-java.jar 升级到 8.0.21 版本。 com.mysql.jdbc.Driver 更换为 com.mysql.cj.jdbc.Driver。 链接 url 里指定 useSSL=false。 链接 url 中显式指定时区，增加 serverTimezone=Asia/Shanghai。  兼容性问题   com.mysql.jdbc.exceptions.jdbc4 在 MySQL Connector 8 中不存在。\n将 mysql-connector-java 版本，升级到 8.0 后，如果项目中有使用 mysql 的 Exception 类，编译时会收到以下错误\nerror: package com.mysql.jdbc.exceptions.jdbc4 does not exist [ERROR] import com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException; [ERROR] import com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException; MySQL 在 8.0 版本重用了现有的 java.sql 异常类，取消了 exceptions.jdbc4 的异常类，整改的异常映射关系如下。\n   5.7 版本异常类 8.0 版本异常类     com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException java.sql.SQLSyntaxErrorException   com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException java.sql.SQLIntegrityConstraintViolationException   com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException java.sql.SQLTransactionRollbackException      数据库关键字扩充问题。\n在适配 MySQL 8.0 的时候遇到如下报错。\nCaused by: java.sql.SQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ', source, i18n_lang' at line 5 问题的原因是：MySQL 新增了一批关键字，在使用过程中，如果字段名称和关键字重复，则需要在字段名称上增加单引号方可使用。RANK 为新增关键字。如下所示：\n\u0026lt;result column=\u0026quot;rank\u0026quot; jdbcType=\u0026quot;INTEGER\u0026quot; property=\u0026quot;rank\u0026quot;/\u0026gt; 新增关键字列表如下。\nACTIVE , ADMIN , ARRAY , ATTRIBUTE , BUCKETS , CLONE , COMPONENT , CUME_DIST (R) , DEFINITION , DENSE_RANK (R) , DESCRIPTION , EMPTY (R) , ENFORCED , ENGINE_ATTRIBUTE , EXCEPT (R) , EXCLUDE , FAILED_LOGIN_ATTEMPTS , FIRST_VALUE (R) , FOLLOWING , GEOMCOLLECTION , GET_MASTER_PUBLIC_KEY , GROUPING (R) , GROUPS (R) , HISTOGRAM , HISTORY , INACTIVE , INVISIBLE , JSON_TABLE (R) , JSON_VALUE , LAG (R) , LAST_VALUE (R) , LATERAL (R) , LEAD (R) , LOCKED , MANAGED , MASTER_COMPRESSION_ALGORITH , MSMASTER_PUBLIC_KEY_PATH , MASTER_TLS_CIPHERSUITES , MASTER_ZSTD_COMPRESSION_LEVEL , MEMBER , NESTED , NETWORK_NAMESPACE , NOWAIT , NTH_VALUE (R) , NTILE (R) , NULLS , OF (R) , OFF , OJ , OLD , OPTIONAL , ORDINALITY , ORGANIZATION , OTHERS , OVER (R) , PASSWORD_LOCK_TIME , PATH , PERCENT_RANK (R) , PERSIST , PERSIST_ONLY , PRECEDING , PRIVILEGE_CHECKS_USER , PROCESS , RANDOM , RANK (R) , RECURSIVE (R) , REFERENCE , REQUIRE_ROW_FORMAT , RESOURCE , RESPECT , RESTART , RETAIN , RETURNING , REUSE , ROLE , ROW_NUMBER (R) , SECONDARY , SECONDARY_ENGINE , SECONDARY_ENGINE_ATTRIBUTE , SECONDARY_LOAD , SECONDARY_UNLOAD , SKIP , SRID , STREAM , SYSTEM (R) , THREAD_PRIORITY , TIES , TLS , UNBOUNDED , VCPU , VISIBLE , WINDOW (R)   "});index.add({'id':4,'href':'/bits-pieces/devops/mysql-large-import/','title':"MySQL大文件导入优化",'content':"项目中需要根据SQL文件导入数据，文件大约20G，正常导入约需要2小时，如何加快导入速度。\n如果一个SQL文件只有一个表的数据，可以直接使用mysql load data infile 语法，速度比较快。\n我们是一个SQL文件包含了很多表，导入过程经过如下设置，20G大约需要40分钟。\n# 进入mysql mysql -u root -p # 创建数据库（如果已经有数据库忽略此步骤） CREATE DATABASE 数据库名; # 设置参数 set sql_log_bin=OFF;//关闭日志 set autocommit=0;//关闭autocommit自动提交模式 0是关闭 1 是开启（默认） set global max_allowed_packet = 20 *1024* 1024 * 1024; # 使用数据库 use 数据库名; # 开启事务 START TRANSACTION; # 导入SQL文件并COMMIT（因为导入比较耗时，导入和COMMIT一行命令） source 文件的路径; COMMIT; "});index.add({'id':5,'href':'/bits-pieces/knives/tldr/','title':"TL;DR",'content':"Too Long; Didn’t Read.\ntldr 根据二八原则，简化了烦琐的 man 指令帮助文档，仅列出常用的该指令的使用方法，让人一看就懂，大多数情况下，给出几个指令的使用 demo 可能正是我们想要的。\n举个例子看下实际运行效果，如下。\n➜ ~ tldr docker Manage Docker containers and images. Some subcommands such as `docker run` have their own usage documentation. More information: \u0026lt;https://docs.docker.com/engine/reference/commandline/cli/\u0026gt;. List currently running docker containers: docker ps List all docker containers (running and stopped): docker ps -a Start a container from an image, with a custom name: docker run --name container_name image Start or stop an existing container: docker start|stop container_name Pull an image from a docker registry: docker pull image Open a shell inside a running container: docker exec -it container_name sh Remove a stopped container: docker rm container_name Fetch and follow the logs of a container: docker logs -f container_name tldr 命令行有多种实现，比如官方推荐的有 npm 和 python。\nnpm install -g tldr pip3 install tldr 个人更喜欢 Rust 版本的实现 tealdeer，支持各系统包管理器和二进制安装，比如 homebrew。\nbrew install tealdeer "});index.add({'id':6,'href':'/bits-pieces/knives/ripgrep/','title':"ripgrep",'content':"ripgrep 简称 rg，是一个面向行的搜索工具，Rust 编写，全平台支持，也是 VS Code 的默认搜索工具。它的搜索性能极高，在大项目中也有着出色的表现，并且默认可以忽略 .gitignore 文件中的内容，非常实用。\n除了作为一个高效的命令行工具使用外，整个项目的设计也不错，另外还是一个学习 Rust 的好项目。\nrg -h 开启探索之旅吧。\n"});index.add({'id':7,'href':'/bits-pieces/knives/','title':"瑞士军刀",'content':"程序员常用优秀工具、软件、类库，上榜都是有理由的。\n"});index.add({'id':8,'href':'/bits-pieces/windows/','title':"Windows",'content':"Windows 下工作常用命令、工具、软件总结。\n"});index.add({'id':9,'href':'/bits-pieces/windows/takeown/','title':"Windows提权 + 设置环境变量",'content':"背景：公司 Windows 办公机受域控安全策略限制，部分文件无权修改，另外开发常用的设置系统环境变量也变灰无法设置。此问题解决方式如下。\n提升文件权限   点击 Windows + X 快捷键 – 选择「命令提示符（管理员）。\n  在 CDM 窗口中执行如下命令。\ntakeown /f C:\\要修复的文件路径   在拿到文件所有权后，还需要使用如下命令获取文件的完全控制权限。\nicacls C:\\要修复的文件路径 /Grant Administrators:F   命令行设置环境变量 Windows 下命令行设置环境变量，方式为 setx 变量名 变量值，变量值带空格等特殊符号的，用引号引起来。\n# 通过命令行设置 Java Home setx JAVA_HOME \u0026#34;C:\\Program Files\\Java\\jdk-11.0.2\u0026#34; # 设置 GO Path setx GOPATH \u0026#34;D:\\workspace\\go\u0026#34; "});index.add({'id':10,'href':'/bits-pieces/kubernetes/cka/','title':"备考 CKA 过程，CKA 真题",'content':"备考 CKA （Certified Kubernetes Administrator）过程，心得，遇见问题，CKA 真题。\n备考环境 备考使用的系统和软件版本如下。\n Ubuntu：20.04 Focal Fossa Kubernetes：1.20.7 kubeadm：1.20.7  安装和使用问题记录 kubeadm 安装问题 安装 kubeadm，国内安装使用阿里镜像源。\n$ cat /etc/apt/sources.list.d/kubernetes.list deb https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main 踩坑：因为使用的是 ubuntu 20.04，代号 focal，专门去各个代理镜像源找kubernetes-focal都没有找到，后来发现 google 官方根本没发布对应的版本，只有kubernetes-xenial， k8s 官方文档里 ubuntu 也是用的这一个版本。可以用，就用他吧。\nkubeadm init 时指定使用阿里镜像源（解决国内连不上 k8s.gcr.io 的问题）、指定版本号(安装考试对应的版本，不一定是最新版本)。\n通过指定--image-repository，不需要手动下载镜像重新打 tag，kubeadm 自动使用指定的 repository。\nkubeadm init --image-repository=registry.aliyuncs.com/google_containers \\  --pod-network-cidr=10.244.0.0/16 \\  --kubernetes-version=v1.20.7 解决 scheduler Unhealthy，controller-manager Unhealthy 第一次安装完成后通过 kubectl get cs命令，发现 scheduler Unhealthy，controller-manager Unhealthy。\n$ kubectl get cs NAME STATUS MESSAGE scheduler Unhealthy Get \u0026quot;http://127.0.0.1:10251/healthz\u0026quot;: dial tcp 127.0.0.1:10 controller-manager Unhealthy Get \u0026quot;http://127.0.0.1:10252/healthz\u0026quot;: dial tcp 127.0.0.1:10 查看本机端口，10251 和 10252 都没有启动。\n确认 schedule 和 controller-manager 组件配置是否禁用了非安全端口。\n查看配置文件，路径分别为：/etc/kubernetes/manifests/kube-scheduler.yaml 和 /etc/kubernetes/manifests/kube-controller-manager.yaml 将两个配置文件中 --port=0 注释掉（注释掉是否合适待商量）。\nspec:containers:- command:- kube-scheduler- --authentication-kubeconfig=/etc/kubernetes/scheduler.conf- --authorization-kubeconfig=/etc/kubernetes/scheduler.conf- --bind-address=127.0.0.1# 注释掉port，其他行原样不要动- --port=0解决 master 无法调度 我的环境是单节点，既当 master 又当 worker，kubeadm 安装完成后默认 master 节点是不参与调度的，pod 会一直 pending。\nkubectl describe node 发现 node 的 Taints 里有 node-role.kubernetes.io/master:NoSchedule。\n设置 k8s master 节点参与 POD 调度。\nkubectl taint nodes your-node-name node-role.kubernetes.io/master- 考试心得   刷新浏览器会导致考试被终止。\n  提前演练敲一遍，时间其实挺紧张。\n  官方kubectl Cheat Sheet章节非常有用，必考。\n  命令自动补全 source \u0026lt;(kubectl completion bash)。\n  尽量使用命令创建 Pod、deployment、service。\nkubectl run podname --image=imagename --restart=Never -n namespace kubectl run \u0026lt;deploymentname\u0026gt; --image=\u0026lt;imagename\u0026gt; -n \u0026lt;namespace\u0026gt; kubectl expose \u0026lt;deploymentname\u0026gt; --port=\u0026lt;portNo.\u0026gt; --name=\u0026lt;svcname\u0026gt;   使用 dry-run。\nkubectl run \u0026lt;podname\u0026gt; --image=\u0026lt;imagename\u0026gt; --restart=Never --dry-run -o yaml \u0026gt; title.yaml   使用 kubectl -h 查看各个命令的帮助，很多都在 Examples 里。比如 kubectl expose -h。\n  CKA 真题练习 真题会过时，别指望着刷刷题就通过考试，老老实实学一遍。\n  将所有 pv 按照 name/capacity 排序。\n# sort by name kubectl get pv --sort-by=.metadata.name # sort by capacity kubectl get pv --sort-by=.spec.capacity.storage   deployment 扩容。\nkubectl scale deployment test --replicas=3   Set the node named ek8s-node-1 as unavaliable and reschedule all the pods running on it.\nkubectl cordon ek8s-node-1 # drain node的时候可能出错，根据错误提示加参数 kubectl drain ek8s-node-1 --delete-local-data --ignore-daemonsets --force   Form the pod label name-cpu-loader,find pods running high CPU workloads and write the name of the pod consuming most CPU to the file /opt/KUTR00401/KURT00401.txt(which alredy exists).\n# 注意题目中并没有提namespace，可以先看下这个label的pod在哪个namespace，确定命令中要不要加namespace kubectl top pods -l name=name-cpu-loader --sort-by=cpu echo '排名第一的pod名称' \u0026gt;\u0026gt;/opt/KUTR00401/KUTR00401.txt   "});index.add({'id':11,'href':'/bits-pieces/','title':"bits and pieces",'content':" \nI always have a lot of bits and pieces in my coat pocket.\n只是些日常琐碎笔记，目前看并没什么大用，翻翻看总还是有惊喜。\nLicense Licensed under CC BY-NC 4.0. 2020-2022 nxest.com.\n"});index.add({'id':12,'href':'/bits-pieces/devops/','title':"DevOps",'content':"DevOps 相关的技术选型、算法研究、实战经验教训。\n"});index.add({'id':13,'href':'/bits-pieces/devops/nexus/','title':"Nexus3 批量导入",'content':"应用场景：\n 从一个可联网镜像仓库迁移到另一个无法联网的镜像仓库，涉及 Java 和 JavaScript 依赖包。 源镜像仓库比较大（10T），新镜像仓库只需要部分依赖，不需要全量导入。  Nexus 配置 Repository 在 nexus 上创建 Java 和 NPM Repository。\n注意：\n 创建时类型选择 hosted。 对于 Java Repository 可根据实际情况将 Version Policy 选择 mixed。 Deployment Policy 选择 Allow redeploy，便于后续重复导入。  导入 Java 依赖包   准备 Java 依赖包：将本地 maven 或 gradle 的存储目录(默认$USER/.m2/repository)清空，重新执行命令，获取干净的 repository。\n  从 nexus-repository-import-scripts 获取 mavenimport.sh 文件。\n  将 mavenimport.sh copy 到 repository 文件夹内\n  执行以下命令开始导入，注意换成自己的 admin 密码，修改端口和 Repository。\ncd repository \u0026amp;\u0026amp; chmod +x mavenimport.sh ./mavenimport.sh -u admin -p admin123 -r http://127.0.0.1:8081/repository/your-repo-name/   以上命令开始导入，可能时间较长，可以去界面上刷新下 jdf 的 repository 看看有没有导进去。\n  导入 NPM 依赖包 导入前端 npm 包就是先下载好各个包的 tgz 文件，然后根据 tgz 文件执行 npm publish。\n  准备前端依赖包：使用这个工具 node-tgz-downloader，根据他的说明，先下载好各个 js 的 .tgz文件，默认下载到一个叫 tarballs 的文件夹内，下载成功后大致结果如下，如果 nodejs 版本比较低可能下载失败，可以尝试使用低版本的 node-tgz-downloader。\ntarballs ├── @babel │ ├── code-frame │ │ ├── code-frame-7.12.11.tgz │ │ └── code-frame-7.16.0.tgz │ ├── compat-data │ │ └── compat-data-7.16.4.tgz │ ├── core │ │ └── core-7.16.0.tgz │ ├── generator │ │ └── generator-7.16.0.tgz │ ├── helper-annotate-as-pure │ │ └── helper-annotate-as-pure-7.16.0.tgz   从 nexus-repository-import-scripts 获取 npmimport.sh 文件。\n  将 npmimport.sh copy 到 tarballs 文件夹内。\n  登录 npm 账户，开始执行导入。\nnpm config set registry=http://127.0.0.1:8081/repository/your-npm-repo/ npm adduser --registry=http://127.0.0.1:8081/repository/your-npm-repo/ cd tarballs \u0026amp;\u0026amp; chmod +x npmimport.sh ./npmimport.sh -r http://127.0.0.1:8081/repository/your-npm-repo/   以上命令开始导入，可能时间较长，可以去界面上刷新下 npm 的 repository 看看有没有导进去。\n  客户端使用 Maven 修改 setting.xml，使用私有仓库。\n另外因为部分包不受自己控制，可能缺少 metadata，执行 mvn package 等命令时，注意增加 -c 参数忽略 checksum。\n如：mvn -c clean package -Dmaven.test.skip=true\n"});index.add({'id':14,'href':'/bits-pieces/devops/superset/','title':"Superset 对接 ClickHouse",'content':"Apache Superset，开源数据分析与可视化平台。\n常用功能：\n SQL 查询，作为一个 Web 版本的 ClickHouse、MySQL 等等多种数据源的客户端。 支持对查询结果再进行过滤，直接 copy 或下载查询结果，保存查询条件，分享查询条件等。 丰富的图表设计、分析。内置各种 Charts 图表，支持自定义 Charts 和 Dashboard，需要自己根据业务动手制作，这才是他的主业。 支持用户管理，基于 RBAC 模型的控制权限。（理论上可以对接 keycloak，看 issue 还不完善可能需要改 python 代码）。  配置文件 全部默认配置文件参考superset/config.py。\n如果想自定义，创建一个 superset_config.py 文件放到 python path。\n中文支持 多语言默认是不打开的（因为维护的不好，英文属于正常维护，其他语言属于有空就维护），需要在 superset_config.py 中增加环境变量，支持中文。\n# 默认中文 BABEL_DEFAULT_LOCALE=\u0026#39;zh\u0026#39; # 支持很多其他语言，裁掉一部分，只留了这两个 LANGUAGES = { \u0026#34;en\u0026#34;: {\u0026#34;flag\u0026#34;: \u0026#34;us\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;English\u0026#34;}, \u0026#34;zh\u0026#34;: {\u0026#34;flag\u0026#34;: \u0026#34;cn\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;中文\u0026#34;}, } "});index.add({'id':15,'href':'/bits-pieces/linux/history/','title':"History入门",'content':"Linux 下 history 命令，用好历史命令提高工作效率。\n搜索历史命令 快捷键 Ctrl + r\n非常建议你使用这个命令, 因为当你曾经输过一个很长的命令之后, 当你再次想输入这个命令的时候, 你就可以按下这个快捷键, 然后键入那条长命令的关键词, 然后就会显示出含有那个关键词的命令, 每次按下这个键都会再往上搜一个。可以找个机器实际体会下，确实很常用。\n重复上一次的命令 向上的方向键。上下键翻看历史命令，翻到想执行的命令回车。\n两个叹号: ！！\n还有这个：！-1\n快捷键：Ctrl+p 或 Ctrl+n，向上和向下翻看历史命令，和上下键效果一样。\n从历史记录中执行某个命令 还是沿袭上一个中的 !-n 模式, 其中 n 是一个编号。如下示例，执行了编号为 4 的命令。\n1 service network restart 2 exit 3 id 4 cat /etc/redhat-release # !4 cat /etc/redhat-release 执行曾经的命令中特定开头的 假设你的部分历史命令如下:\n1721 find . -type f 那么, 怎样重复执行 1721 条呢? 除了利用 !-1721 这么麻烦的方法，我们还可以用 !f 这样的姿势。因为开头的 f 是离着最后一条命令最近的, 所以 !f 就执行了它。\n清空历史记录 history -c 在历史记录中显示时间 我们可以用 HISTTIMEFORMAT 这个变量来定义显示历史记录时的时间参数:\n# export HISTTIMEFORMAT='%F %T ' # history 也可以用下面的别名来定义显示历史命令的数量:\nalias h1='history 10' 用 HISTCONTROL 来删除重复的历史记录 下面的例子中, 有三个 pwd 命令, 那么在 history 中就会显示三次 pwd , 有点不那么人性化。\n# pwd # pwd # pwd # history | tail -4 44 pwd 45 pwd 46 pwd 47 history | tail -4 所以我们可以这样修改:\nexport HISTCONTROL=ignoredups 然后就不会出现相邻的重复记录了。\nHistory 扩展和总结 用这个功能可以选择特定的历史记录, 不论是修改还是立即执行, 都可以完成。\n!! 重复上一条命令。\n!10 重复历史记录中第 10 条命令。\n!-2 重复历史记录中倒数第二条命令。\n!string 重复历史记录中最后一条以 string 开头的命令。\n!?string 重复历史记录中最后一条包含 string 的命令。\n"});index.add({'id':16,'href':'/bits-pieces/kubernetes/','title':"Kubernetes",'content':""});index.add({'id':17,'href':'/bits-pieces/linux/','title':"Linux",'content':"Linux 下工作常用命令、工具、软件总结。\nUbuntu Ubuntu 查询指定软件有多少可用版本:\napt-cache madison \u0026lt;\u0026lt;package name\u0026gt;\u0026gt; 安装软件时指定版本号：\n$ apt-get install \u0026lt;\u0026lt;package name\u0026gt;\u0026gt;=\u0026lt;\u0026lt;version\u0026gt;\u0026gt; # apt-get install kubeadm=1.20.7-00 查看 Ubuntu 版本代号：\n$ sb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.2 LTS Release: 20.04 Codename: focal "});index.add({'id':18,'href':'/bits-pieces/linux/shell-coding/','title':"Shell 编程实用句式",'content':"选婿。\n#!/usr/bin/env bash  #!/usr/bin/bash 检查是否以 root 用户执行。\n# check if run as root user if [[ `id -u` -ne 0 ]]; then echo \u0026#34;You need root privileges to run this script.\u0026#34; fi 获取正在执行脚本的绝对路径，注意直接用 $0 或 pwd 获取的可能都不要你想要的。\ncurrent_dir=$(cd `dirname $0`;pwd) 为当前目录包含子目录下所有 .sh 文件增加可执行权限。\nchmod +x `find . -name \u0026#39;*.sh\u0026#39;` 将提示信息显示到终端（控制台），同时也写入到文件里。\nlog_file=/var/log/test.log echo \u0026#34;This line will echo to console and also write to log file.\u0026#34; | tee -a ${log_file} 类似于 Java properties 中 key=value 形式的字符串，取 key 和 value 的值。\nusername_line=\u0026#34;username=test\u0026#34; #key is username key=${username_line%=*} #val is test val=${username_line#*=} 实现 trim 效果。\n#trim string by echo val_trim=$(echo -n ${val}) 字体输出颜色及终端格式控制\n#字体色范围：30-37 echo -e \u0026#34;\\033[30m 黑色字 \\033[0m\u0026#34; echo -e \u0026#34;\\033[31m 红色字 \\033[0m\u0026#34; echo -e \u0026#34;\\033[32m 绿色字 \\033[0m\u0026#34; echo -e \u0026#34;\\033[33m 黄色字 \\033[0m\u0026#34; echo -e \u0026#34;\\033[34m 蓝色字 \\033[0m\u0026#34; echo -e \u0026#34;\\033[35m 紫色字 \\033[0m\u0026#34; echo -e \u0026#34;\\033[36m 天蓝字 \\033[0m\u0026#34; echo -e \u0026#34;\\033[37m 白色字 \\033[0m\u0026#34; #字背景颜色范围：40-47 echo -e \u0026#34;\\033[40;37m 黑底白字 \\033[0m\u0026#34; echo -e \u0026#34;\\033[41;30m 红底黑字 \\033[0m\u0026#34; echo -e \u0026#34;\\033[42;34m 绿底蓝字 \\033[0m\u0026#34; echo -e \u0026#34;\\033[43;34m 黄底蓝字 \\033[0m\u0026#34; echo -e \u0026#34;\\033[44;30m 蓝底黑字 \\033[0m\u0026#34; echo -e \u0026#34;\\033[45;30m 紫底黑字 \\033[0m\u0026#34; echo -e \u0026#34;\\033[46;30m 天蓝底黑字 \\033[0m\u0026#34; echo -e \u0026#34;\\033[47;34m 白底蓝字 \\033[0m\u0026#34; "});index.add({'id':19,'href':'/bits-pieces/linux/tcpdump/','title':"tcpdump",'content':"tcpdump 捕捉网卡eth0流量，并存入到out.pcap文件中。\nsudo tcpdump -vv -s0 -i eth0 -w out.pcap "});index.add({'id':20,'href':'/bits-pieces/kubernetes/tldr/','title':"TL;DR",'content':"复制\u0026ndash;粘贴，这就是生活。\n 复制 secret 到另一个 namespace。\nkubectl get secret mys --namespace=na -oyaml | grep -v \u0026#39;^\\s*namespace:\\s\u0026#39; | kubectl apply --namespace=nb -f - 批量删除 pod。\nkubectl get pods --all-namespaces | grep Evicted | awk \u0026#39;{print $2 \u0026#34; --namespace=\u0026#34; $1}\u0026#39; | xargs kubectl delete pod # Delete by label kubectl delete pod -n idaas-book -l app.kubernetes.io/name=idaas-book 密钥解密。\nkubectl get secret my-creds -n mysql -o jsonpath=\u0026#34;{.data.ADMIN_PASSWORD}\u0026#34; | base64 --decode Docker 保存和导入镜像。\n# save image(s) docker save image:tag image2:tag | gzip \u0026gt;xxx.tar.gz # load images docker load -i xxx.tar.gz "});index.add({'id':21,'href':'/bits-pieces/linux/tar.gz/','title':"文件压缩解压",'content':"常用文件格式 .tar：tar 其实打包（或翻译为归档）文件，本身并没有压缩。在 Linux 里 man tar 可以看到它的描述也是“manipulate tape archives”（tar 最初被用来在磁带上创建档案，现在，用户可以在任何设备上创建档案，只是它的描述还没有改）。\n.gz：gzip 是 GNU 组织开发的一个压缩程序，.gz 结尾的文件就是 gzip 压缩的结果。\n.bz2：bzip2 是一个压缩能力更强的压缩程序，.bz2 结尾的文件就是 bzip2 压缩的结果。\n.Z：compress 也是一个压缩程序。.Z 结尾的文件就是 compress 压缩的结果。\n.zip：使用 zip 软件压缩的文件。\n.tar.gz、.tar.bz2、.tar.xz 等可以理解为打包+压缩的效果，用软件解压可以发现比.gz 多了一层包。gzip 和 bzip2，不能同时压缩多个文件，tar 相当于开个挂加上同时压缩的特效，tar 先归档为一个大文件，而归档为大文件的速度是很快的，测试了一下几乎可以忽略不计。\n除了这些格式外，常见的 deb、exe、msi、rpm、dmg、iso 等安装软件，其实都是经过压缩的，一般情况下没有必要再压缩。而 rar 基本认为是 Windows 平台专属的压缩算法了，各个 Linux 发行版都不自带 rar 压缩解压缩软件，所以可以看到很多软件发行的格式都是 .tar.gz 或 .zip。\n解压缩 根据文件名后缀自行选择解压缩命令。\ntar -xf test.tar gzip -d test.gz gunzip test.gz # -C 直接解压到指定目录 tar -xzf test.tar.gz -C /home bzip2 -d test.bz2 bunzip2 test.bz2 tar -xjf test.tar.bz2 tar -xvJf test.tar.xz 压缩 请根据需要选择压缩算法。\n# 将当前目录下所有jpg格式的文件打包为pictures.tar tar -cf pictures.tar *.jpg # 将Picture目录下所有文件打包并用gzip压缩为pictures.tar.gz tar -czf pictures.tar.gz Picture/ # 将Picture目录下所有文件打包并用bzip2压缩为pictures.tar.bz2 tar -cjf pictures.tar.bz2 Picture/ "});index.add({'id':22,'href':'/bits-pieces/linux/pngquant/','title':"PNG图片批量压缩",'content':"使用 pngquant 命令行批量压缩 PNG 图片。\npngquant 压缩当前目录下全部 PNG 文件，并且默认全覆盖已有。\nfor file in $(ls *.png) do pngquant $file --force --output $file done "});index.add({'id':23,'href':'/bits-pieces/linux/transaction/','title':"数据库事务控制",'content':"数据库事务总结，主要包括数据库事务 ACID 属性介绍、数据库并发问题总结、事务传播行为和隔离级别。\n概念 事务（Transaction）是并发控制的基本单位。它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。标准定义：指作为单个逻辑工作单元执行的一系列操作，而这些逻辑工作单元需要具有原子性， 一致性，隔离性和持久性四个属性，统称为 ACID 特性。\nAtomic（原子性） 事务中包含的操作被看做一个不可分割的逻辑单元，这个逻辑单元中的操作要么全部成功，要么全部失败。\nConsistency（一致性） 事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。只有合法的数据可以被写入数据库，否则事务应该将其回滚到最初状态。关于数据库一致性，更专业的解释请参考专业的书籍。\nIsolation（隔离性） 事务允许多个用户对同一个数据进行并发访问，而不破坏数据的正确性和完整性。同时，并行事务的修改必须与其他并行事务的修改相互独立。\nDurability（持久性） 事务提交后，对系统的影响是永久的。简单理解就是写进去了，不会因为时间、系统环境，关机重启等变化而变化。\n数据库并发问题 数据库是共享资源，通常有许多个事务同时在运行。当多个事务并发地存取数据库时就会产生同时读取和（或）修改同一数据的情况。若对并发操作不加控制就可能会存取和存储不正确的数据，破坏数据库的一致性。所以数据库管理系统必须提供并发控制机制。\n并发操作一般可能带来以下几种问题。为说明问题，先来准备一个例子，假设现在有一个账户表 TBL_BANK_ACCOUNT。\nCREATE TABLE TBL_BANK_ACCOUNT（ AccountId CHAR(4) NOT NULL, -- 银行账号 Username NVARCHAR(63) NOT NULL, -- 用户名 Balance BIGINT NOT NULL -- 余额 ) INSERT INTO TBL_BANK_ACCOUNT VALUES (\u0026#39;9555\u0026#39;, \u0026#39;小明\u0026#39;, 1000) -- 北京分行账号 INSERT INTO dbo.BankAccount VALUES (\u0026#39;9556\u0026#39;, \u0026#39;小明\u0026#39;, 2000) -- 上海分行账号 脏读（Dirty reads） 一个事务读到另一个事务未提交的更新数据。\n   事务 1 取款事务 事务 2 工资转账事务     开始事务     开始事务   查询余额 1000 元    取出 100 变为 900     查询余额为 900   异常发生，事务回滚，余额恢复为 1000     汇入工资 2000 元，余额为 2900    提交事务，最终余额 2900，损失了 100    不可重复读（Non-Repeatable Reads） 在同一个事务内，读取表中的某一行记录，多次读取的结果不同。与幻读区别的重点在于修改，同样的条件，已经读取过的数据，再次读取出来和上一次的值不一样。\n   事务 1 工资计算 事务 2 汇款和通知      开始事务   开始事务 查询工资 2000 元，通知银行汇款 2000   增加加班费 6000 元    提交事务     再次查询工资应发 8000 元，邮件通知员工本月发了 8000 元    提交事务    幻读(Phantom Reads) 一个事务读到另一个事务已提交的新插入的数据,导致前后不一致。与不可重复读有点类似，都是两次读取。区别的重点在于增加或者删除。\n   事务 1 加班录入 事务 2 加班天数统计，计算加班费      开始事务   开始事务 统计员工小明加班 3 天    通知银行发 3 天的加班费   增加一天加班数据    提交事务     再次统计加班天数，是 4 天，通知小明发了 4 天的加班费    提交事务    事务隔离级别 事务隔离级别(Transaction Isolation Level)就是对事务并发控制的等级。标准组织 ANSI 定义了四个隔离级别，读未提交 Read uncommitted、读已提交 Read committed、可重复读 Repeatable read、串行化(序列化)Serializable，这四个级别严格程度越来越高，同时并发性能越来越低。\n读未提交 Read uncommitted 一个事务在执行过程中可以看到其他事务没有提交的记录。\n读已提交 Read committed 只能读已提交的数据。但是读取的数据可以被其他事务修改，这样也就会导致不可重复读。\n可重复读 Repeatable read 所有被 Select 获取的数据都不能被修改。\n序列化 Serializable 所有事务一个接一个的执行。\n数据库并发问题还有常说的第一类更新丢失、第二类更新丢失，为减少概念复杂度，在这里没有列出来。\n各个隔离级别和问题对应，√: 可能出现，×: 不会出现\n    脏读 不可重复读 幻读     Read uncommitted √ √ √   Read committed × √ √   Repeatable read × × √   Serializable × × ×    Oracle 和 SqlServer 默认隔离级别是读已提交，MySql 默认隔离级别是可重复读。\nOracle 只支持 READ COMMITTED 和 SERIALIZABLE 这两种标准隔离级别，另外增加了一个非标准的“只读(read-only)”隔离级别。顺便提一句，他的 Serializable 隔离级别，并不真正阻塞事务的执行（更深层次的理解另外单说）。\n为避免幻读和不可重复读问题，一般是在一个事务里确保只读取数据一次，而不是提高事务的隔离级别。 况且 Oracle 也没法设置 Repeatable read。\n事务传播行为  PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。Spring 默认的事务传播行为。 PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。 PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。 PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。 PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与 PROPAGATION_REQUIRED 类似的操作。  嵌套事务 嵌套是子事务套在父事务中执行，子事务是父事务的一部分，在进入子事务之前，父事务建立一个回滚点，叫 save point，然后执行子事务，这个子事务的执行也算是父事务的一部分，然后子事务执行结束，父事务继续执行。重点就在于那个 save point。看几个问题就明了了：\n 如果子事务回滚，会发生什么？  父事务会回滚到进入子事务前建立的 save point，然后尝试其他的事务或者其他的业务逻辑，父事务之前的操作不会受到影响，更不会自动回滚。\n  如果父事务回滚，会发生什么？  父事务回滚，子事务也会跟着回滚！为什么呢，因为父事务结束之前，子事务是不会提交的，我们说子事务是父事务的一部分，正是这个道理。那么：\n  事务的提交，是什么情况？  是父事务先提交，然后子事务提交，还是子事务先提交，父事务再提交？答案是第二种情况，还是那句话，子事务是父事务的一部分，由父事务统一提交。\n   只读事务 readOnly 概念：从这一点设置的时间点开始到这个事务结束的过程中，其他事务所提交的数据，该事务将看不见。\n应用场合：\n 如果你一次执行单条查询语句，则没有必要启用事务支持，数据库默认支持 SQL 执行期间的读一致性； 如果你一次执行多条查询语句，例如统计查询，报表查询，在这种场景下，多条查询 SQL 必须保证整体的读一致性，否则，在前条 SQL 查询之后，后条 SQL 查询之前，数据被其他用户改变，则该次整体的统计查询将会出现读数据不一致的状态，此时，应该启用事务支持。  总结：\n readonly 并不是所有数据库都支持的，不同的数据库下会有不同的结果。 设置了 readonly 后，connection 都会被赋予 readonly，效果取决于数据库的实现。 在 ORM 中，设置了 readonly 会赋予一些额外的优化，例如在 Hibernate 中，会被禁止 flush 等。 由于只读事务不存在数据的修改，因此数据库将会为只读事务提供一些优化手段，例如 Oracle 对于只读事务，不启动回滚段，不记录回滚 log。  Spring 声明式事务 Spring 提供了编程式事务和声明式事务两种机制。为便于理解，简单回顾下 JDBC 和 Hibernate 的事务管理方式。\n JDBC 方式：  Connection conn = DataSourceUtils.getConnection(); //开启事务 conn.setAutoCommit(false); try { Object retVal = callback.doInConnection(conn); conn.commit(); //提交事务  return retVal; }catch (Exception e) { conn.rollback();//回滚事务  throw e; }finally { conn.close(); }  Hibernate 方式：  Session session = null; Transaction transaction = null; try { session = factory.openSession(); //开启事务  transaction = session.beginTransaction(); transation.begin(); session.save(user); transaction.commit();//提交事务 } catch (Exception e) { transaction.rollback();//回滚事务  return false; }finally{ session.close(); } 看下 Spring 编程式方式：\n//1.获取事务管理器 PlatformTransactionManager txManager =ctx.getBean(\u0026#34;txManager\u0026#34;); //2.定义事务属性 DefaultTransactionDefinition td = new DefaultTransactionDefinition(); td.setIsolationLevel(TransactionDefinition.ISOLATION_READ_COMMITTED); //3开启事务,得到事务状态 TransactionStatus status = txManager.getTransaction(td); try { //4.执行数据库操作  jdbcTempate.queryForInt(\u0026#34;select count(*) from tbl_doc\u0026#34;); //5、提交事务  txManager.commit(status); }catch (Exception e) { //6、回滚事务  txManager.rollback(status); } 可以看到，以上几种方式都比较复杂，需要我们自己处理事务，要做的事情比较多。而 Spring 的声明式事务使用简单，它支持注解和 xml 配置，这里以注解为例。\n@Transactional Spring 声明式事务的使用，一切都落在注解**@Transactional**上。\n先看一个简单的例子，在实现类的加注解，实现事务控制。\n\u0026lt;!-- the service class that we want to make transactional --\u0026gt; @Transactional public class DefaultFooService implements FooService { Foo getFoo(String fooName); Foo getFoo(String fooName, String barName); void insertFoo(Foo foo); void updateFoo(Foo foo); } 使用方法  @Transactional 可用于接口、接口方法、实现类以及类方法上。放在接口或类上，相当于为此接口或类下所有的 public 方法都加了这样一个注解。 Spring 团队的建议是你在具体的类（或类的方法）上使用 @Transactional 注解，而不要使用在类所要实现的任何接口上。你当然可以在接口上使用 @Transactional 注解，但是这将只能当你设置了基于接口的代理时它才生效。因为注解是不能继承的，这就意味着如果你正在使用基于类的代理时，那么事务的设置将不能被基于类的代理所识别，而且对象也将不会被事务代理所包装（将被确认为严重的）。因此，请接受 Spring 团队的建议并且在具体的类上使用@Transactional 注解。 @Transactional 注解应该只被应用到 public 的方法上。 如果你在 protected、private 或者 package-visible 的方法上使用，它也不会报错，也不会生效。 方法的@Transactional 会覆盖类上面声明的事务，也就是方法上的优先级高。  传播行为（Propagation） 所谓事务传播行为就是多个事务方法相互调用时，事务如何在这些方法间传播。Spring 支持 7 种事务传播行为：\n PROPAGATION_REQUIRED 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY 使用当前的事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则开启一个新的事务。PROPAGATION_NESTED 开始一个 \u0026ldquo;嵌套的\u0026rdquo; 事务, 它是已经存在事务的一个真正的子事务. 潜套事务开始执行时, 它将取得一个 savepoint. 如果这个嵌套事务失败, 我们将回滚到此 savepoint. 潜套事务是外部事务的一部分, 只有外部事务结束后它才会被提交. 嵌套事务回滚不影响外部事务，但外部事务回滚将导致嵌套事务回滚。 使用嵌套事务需要 JDBC3.0 并且事务管理器开启嵌套事务（常用的 JpaTransactionManager 和 HibernateTransactionManager 默认是不开启的），如果没有开启，运行时将抛出异常。  举例，现有用户和地址管理，假如每增加一个新用户就需要自动增加一个与此用户相关的地址（这例子真挫，至今没有见到过这样的需求）。那么代码大致是这个样子：\n//用户管理类 public class UserService { @Resource private UserDao userDao; /** 地址管理类 */ @Resource private AddressService addressService; @Transactional public void save(User user){ //执行sql保存用户信息  userDao.add(user); Address address=new Address();//设置地址信息  //执行sql保存地址信息  addressService.save(address); } } //测试类 public class ApplicationTest { @Resource private UserService userService; @Test public void transactionalTest() { User user = new User(); user.setUsername(\u0026#34;Test-001\u0026#34;); userService.save(user); } } @Transactional 注解加在 UserService.save 和 AddressService.save 两个方法上。\n具体的事务开启和关闭流程，设置 spring 的日志级别为 debug 后，运行，可看到类似于这面这样的日志。这里使用了 Spring data jpa，打印的是 JpaTransactionManager 的日志。UserServices 使用的传播行为是 REQUIRED，AddressService 使用 REQUIRES_NEW。\n- Creating new transaction with name [UserService.save]:PROPAGATION_REQUIRED,ISOLATION_DEFAULT; '' - Opened new EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@16602333] for JPA transaction - Exposing JPA transaction as JDBC transaction [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@2dd4a7a9] - Found thread-bound EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@16602333] for JPA transaction - Participating in existing transaction - Found thread-bound EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@16602333] for JPA transaction - Suspending current transaction, creating new transaction with name [AddressService.save] - Opened new EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@28b7646] for JPA transaction - Exposing JPA transaction as JDBC transaction [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@40239b34] - Found thread-bound EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@28b7646] for JPA transaction - Participating in existing transaction - Initiating transaction commit - Committing JPA transaction on EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@28b7646] - Closing JPA EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@28b7646] after transaction - Closing JPA EntityManager - Resuming suspended transaction after completion of inner transaction - Initiating transaction commit - Committing JPA transaction on EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@16602333] - Closing JPA EntityManager [org.hibernate.jpa.internal.EntityManagerImpl@16602333] after transaction "});index.add({'id':24,'href':'/bits-pieces/linux/regular-expressions/','title':"Regular Expressions",'content':"正则表达式从入门到放弃 首先来看几个问题：\n 假设有一个字符串“a b c”(中间是一个空格)，想实现按空格分割成一个数组[\u0026ldquo;a\u0026rdquo;,\u0026ldquo;b\u0026rdquo;,\u0026ldquo;c\u0026rdquo;]，用 Java 或 JavaScript 代码如何实现。 原始数组改成\u0026quot;a b c\u0026quot;(中间是 N 个空格)，仍分割成数组[\u0026ldquo;a\u0026rdquo;,\u0026ldquo;b\u0026rdquo;,\u0026ldquo;c\u0026rdquo;]，如何实现。  @Test public void testSplit() { String dotStr = \u0026#34;a.b.c\u0026#34;; assertEquals(dotStr.split(\u0026#34;.\u0026#34;).length, 0); assertEquals(dotStr.split(\u0026#34;\\\\.\u0026#34;).length, 3); String spaceStr=\u0026#34;a b c\u0026#34;;//a与b之间两个空格,b与c之间一个空格  assertEquals(spaceStr.split(\u0026#34; \u0026#34;).length, 4);//一个空格  assertEquals(spaceStr.split(\u0026#34; +\u0026#34;).length, 3);//一个或多个空格  assertEquals(\u0026#34;a b c\u0026#34;.split(\u0026#34; +\u0026#34;).length, 3);//一个或多个空格  assertEquals(\u0026#34;a b c\u0026#34;.split(\u0026#34; +\u0026#34;).length, 3);//一个或多个空格  //顺便提一句,与正则无关,注意下面这个结果,这是Java的split方法自己处理的  assertEquals(\u0026#34;a b c \u0026#34;.split(\u0026#34; \u0026#34;).length, 3);//split会去除最后为空的结果  assertEquals(\u0026#34; a b c\u0026#34;.split(\u0026#34; \u0026#34;).length, 4);//split不会去除前面为空的结果  } 以上就是一个正则的简单应用，其实平时工作中除了编程我们也会经常用到正则，比如搜索所有 Word 文档（*.doc）,在文本编辑器中搜索和替换文字等等。正则表达式经过数年的发展，已经逐渐从模糊而深奥的数学概念，发展成为在计算机各类工具和软件包应用中的主要功能，成为人们工作中的一个利器。\n什么是正则表达式 正则表达式（Regular Expression，regex、regexp，以下简称正则）是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。\n完整的正则表达式由两种字符构成，特殊字符（又译元字符）和普通文字。如果把正则表达式想象成普通的语言，普通文字相当于语言中的单词，而元字符相当于语法。就像一门语言一样，正则是烦琐而强大的，学会之后的应用会让你除了提高效率外，会给你带来绝对的成就感。只要坚持去学，一定会放弃的。\n正则引擎 引擎就相当于语言的编译器，解释器，用来对正则进行语法分析。不同的引擎决定了某个正则能否匹配、在何处匹配，以及匹配成功或报告失败的速度，另外知道正则表达式引擎是如何工作的有助于理解为何某个正则表达式在一个平台好用，换个平台就不好使了。\n正则引擎主要可以分为两大类：一种是 DFA，一种是 NFA。先别管这两个的含义，只需要知道这两个名字。这两种引擎都有了很长的历史，当中也由这两种引擎产生了很多变体。后来又出了一个 POSIX 标准，用来规范这种现象。DFA 是符合这种标准的，NFA 不符合，这样一来，主流的正则引擎又分为 3 类：DFA，传统型 NFA，POSIX NFA。\n关于 DFA 和 NFA 的详细区别，在这里先不提了，因为正则本身就是一个很难懂的语言，一下子提这么多怕大家真的放弃了。但是要了解一点，不同的引擎不同的写法，速度是不一样的，如果对性能要求高的话，还是需要了解引擎的实现方式。Java 和 JavaScript 都是 NFA 类型。除去引擎的不同，不同的语言对正则的实现也有差异，所以下面所有的语法和实例，多以 Java 为主，尽量兼顾 JavaScript，不考虑 Python、C++、Swift 等其他语言。\n基础语法    元字符 说明     ^ 匹配输入字符串开始的位置。   $ 匹配输入字符串结尾的位置。   _ 零次或多次匹配前面的字符或子表达式。例如，zo_ 匹配\u0026quot;z\u0026quot;和\u0026quot;zoo\u0026quot;。* 等效于 {0,}。   + 一次或多次匹配前面的字符或子表达式。例如，\u0026ldquo;zo+\u0026ldquo;与\u0026quot;zo\u0026quot;和\u0026quot;zoo\u0026quot;匹配，但与\u0026quot;z\u0026quot;不匹配。+ 等效于 {1,}。   ? 零次或一次匹配前面的字符或子表达式。例如，\u0026ldquo;do(es)?\u0026ldquo;匹配\u0026quot;do\u0026quot;或\u0026quot;does\u0026quot;中的\u0026quot;do\u0026rdquo;。? 等效于 {0,1}。   {n} n 是非负整数。正好匹配 n 次。例如，\u0026ldquo;o{2}\u0026ldquo;与\u0026quot;Bob\u0026quot;中的\u0026quot;o\u0026quot;不匹配，但与\u0026quot;food\u0026quot;中的两个\u0026quot;o\u0026quot;匹配。   {n,} n 是非负整数。至少匹配 n 次。例如，\u0026ldquo;o{2,}\u0026ldquo;不匹配\u0026quot;Bob\u0026quot;中的\u0026quot;o\u0026rdquo;，而匹配\u0026quot;foooood\u0026quot;中的所有 o。\u0026ldquo;o{1,}\u0026ldquo;等效于\u0026quot;o+\u0026quot;。\u0026ldquo;o{0,}\u0026ldquo;等效于\u0026quot;o*\u0026quot;。   {n,m} M 和 n 是非负整数，其中 n \u0026lt;= m。匹配至少 n 次，至多 m 次。注意：您不能将空格插入逗号和数字之间。   ? 当此字符紧随任何其他限定符（*、+、?、{n}、{n,}、{n,m}）之后时，匹配模式是\u0026quot;非贪心的\u0026rdquo;。\u0026ldquo;非贪心的\u0026quot;模式匹配搜索到的、尽可能短的字符串，而默认的\u0026quot;贪心的\u0026quot;模式匹配搜索到的、尽可能长的字符串。例如，在字符串\u0026quot;oooo\u0026quot;中，\u0026ldquo;o+?\u0026ldquo;只匹配单个\u0026quot;o\u0026rdquo;，而\u0026quot;o+\u0026ldquo;匹配所有\u0026quot;o\u0026rdquo;。   . 匹配除\u0026rdquo;\\r\\n\u0026quot;之外的任何单个字符。若要匹配包括\u0026rdquo;\\r\\n\u0026quot;在内的任意字符，请使用诸如\u0026rdquo;[\\s\\S]\u0026ldquo;之类的模式。   (pattern) 匹配 pattern 并捕获该匹配的子表达式。可以使用 $0…$9 属性从结果\u0026quot;匹配\u0026quot;集合中检索捕获的匹配。若要匹配括号字符 ( )，请使用\u0026rdquo;(\u0026ldquo;或者\u0026rdquo;)\u0026quot;。   x│y 匹配 x 或 y。例如'(z│f)ood' 匹配\u0026quot;zood\u0026quot;或\u0026quot;food\u0026rdquo;。   [xyz] 字符集。匹配包含的任一字符。例如，\u0026quot;[abc]\u0026ldquo;匹配\u0026quot;plain\u0026quot;中的\u0026quot;a\u0026rdquo;。   [^xyz] 反向字符集。匹配未包含的任何字符。例如，\u0026quot;[^abc]\u0026ldquo;匹配\u0026quot;plain\u0026quot;中\u0026quot;p\u0026rdquo;，\u0026ldquo;l\u0026rdquo;，\u0026ldquo;i\u0026rdquo;，\u0026ldquo;n\u0026rdquo;。   [a-z] 字符范围。匹配指定范围内的任何字符。例如，\u0026quot;[a-z]\u0026ldquo;匹配\u0026quot;a\u0026quot;到\u0026quot;z\u0026quot;范围内的任何小写字母。   [^a-z] 反向范围字符。匹配不在指定的范围内的任何字符。例如，\u0026quot;[^a-z]\u0026ldquo;匹配任何不在\u0026quot;a\u0026quot;到\u0026quot;z\u0026quot;范围内的任何字符。   \\b 匹配一个字边界，即字与空格间的位置。例如，\u0026ldquo;er\\b\u0026quot;匹配\u0026quot;never\u0026quot;中的\u0026quot;er\u0026rdquo;，但不匹配\u0026quot;verb\u0026quot;中的\u0026quot;er\u0026rdquo;。   \\B 非字边界匹配。\u0026ldquo;er\\B\u0026quot;匹配\u0026quot;verb\u0026quot;中的\u0026quot;er\u0026rdquo;，但不匹配\u0026quot;never\u0026quot;中的\u0026quot;er\u0026rdquo;。   \\d 数字字符匹配。等效于 [0-9]。   \\D 非数字字符匹配。等效于 [^0-9]。   \\f 换页符匹配。等效于 \\x0c 和 \\cL。   \\n 换行符匹配。等效于 \\x0a 和 \\cJ。   \\r 匹配一个回车符。等效于 \\x0d 和 \\cM。   \\s 匹配任何空白字符，包括空格、制表符、换页符等。   \\S 匹配任何非空白字符。   \\t 制表符匹配。   \\w 匹配任何字类字符，包括下划线。与\u0026rdquo;[A-Za-z0-9_]\u0026ldquo;等效。   \\W 与任何非单词字符匹配。与\u0026rdquo;[^a-za-z0-9_]\u0026ldquo;等效。    运算符优先级 正则表达式从左到右进行计算，并遵循优先级顺序，这与算术表达式非常类似。相同优先级的从左到右进行运算，不同优先级的运算先高后低。下表从最高到最低说明了各种正则表达式运算符的优先级顺序.\n"});index.add({'id':25,'href':'/bits-pieces/categories/','title':"Categories",'content':""});index.add({'id':26,'href':'/bits-pieces/tags/','title':"Tags",'content':""});})();